{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9952a90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "from datetime import datetime\n",
    "import pingouin as pg\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pingouin import ttest\n",
    "\n",
    "from bmp_config import path_data, envcode2env\n",
    "from bmp_behav_proc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874445a9",
   "metadata": {},
   "source": [
    "# Variability (compare with Tan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b985d646",
   "metadata": {},
   "source": [
    "## corr ES and variance (and other statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1dfc91",
   "metadata": {},
   "source": [
    "### fixed histlen across subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2c5adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "load = 1\n",
    "if load:\n",
    "    fnf_fhl = pjoin(path_data,'dfcs_fixhistlen.pkl')\n",
    "    print(fnf_fhl)\n",
    "    print( str(datetime.fromtimestamp(os.stat(fnf_fhl).st_mtime)))\n",
    "    dfcs_fixhistlen = pd.read_pickle(fnf_fhl )\n",
    "else:\n",
    "    fnf = pjoin(path_data,'df_all_multi_tsz__.pkl.zip')\n",
    "    print(fnf)\n",
    "    print( str(datetime.fromtimestamp(os.stat(fnf).st_mtime)))\n",
    "    df_all_multi_tsz = pd.read_pickle(fnf)\n",
    "    df = df_all_multi_tsz.query('trial_shift_size == 1 and trial_group_col_calc == \"trialwe\" '\n",
    "                            ' and retention_factor_s == \"0.924\"').copy().sort_values(['subject','trials'])\n",
    "    df,dfall,ES_thr,envv,pert = addBehavCols2(df);\n",
    "    dfc = df.copy()\n",
    "    dfcs,dfcs_fixhistlen,dfcs_fixhistlen_untrunc,histlens  = addWindowStatCols(dfc, ES_thr, \n",
    "                                        varn0s = ['error','error_pscadj','error_pscadj_abs'])\n",
    "    dfcs_fixhistlen, me_pct_excl = truncLargeStats(dfcs_fixhistlen_untrunc, histlens, 5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bf984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg\n",
    "dfcs_fixhistlen['environment'] = dfcs_fixhistlen['environment'].astype(int)\n",
    "df_ = dfcs_fixhistlen[['environment','subject','trials','error_pscadj_abs_Tan29']]\n",
    "assert not df_.duplicated(['subject','trials']).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb618753",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_suffixes = 'mav,std,invstd,mavsq,mav_d_std,mav_d_var,Tan,invmavsq,invmav,std_d_mav,invTan'.split(',')\n",
    "\n",
    "varn0 = 'error_pscadj'\n",
    "n = 3\n",
    "for suffix in all_suffixes:\n",
    "    s = f'{varn0}_{suffix}{n}'\n",
    "    if s not in dfcs_fixhistlen.columns:\n",
    "        print(s)\n",
    "    assert s in dfcs_fixhistlen.columns\n",
    "\n",
    "print( all_suffixes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8091877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "prl = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b1feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make prev error abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09228f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcs_fixhistlen.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371e0a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "[col for col in dfcs_fixhistlen.columns if col.endswith('error_mav4')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef3de02",
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# run long calc\n",
    "from joblib import Parallel, delayed\n",
    "from itertools import product\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning    \n",
    "from numpy.linalg import LinAlgError\n",
    "import traceback\n",
    "import gc\n",
    "gc.collect()\n",
    "n_jobs_inside = 1\n",
    "\n",
    "# Define the function to be executed in parallel\n",
    "def run_model(args, ret_res = False):\n",
    "    dfcs_fixhistlen, cocoln, std_mavsz_, varn0, varn_suffix = args\n",
    "    varn = f'{varn0}_{varn_suffix}{std_mavsz_}'\n",
    "    df_ = dfcs_fixhistlen.dropna(subset=[varn, 'err_sens'])\n",
    "    df_ = df_[~np.isinf(df_[varn])]\n",
    "\n",
    "    excfmt = None\n",
    "    nstarts = 1\n",
    "    result = None\n",
    "    if cocoln == 'None':\n",
    "        s,s2 = f\"err_sens ~ {varn}\",\"1\"\n",
    "        model = smf.mixedlm(s, df_, \n",
    "                    groups=df_[\"subject\"])\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings('ignore',category=ConvergenceWarning)\n",
    "            result = model.fit()\n",
    "        results = {(s,s2): result}\n",
    "    else:\n",
    "        flas = []\n",
    "        s,s2 = f\"err_sens ~ C({cocoln}) + {varn} + C({cocoln}) * {varn} + {varn} * prev_error_pscadj_abs\",\\\n",
    "            f\"~C({cocoln})\"; flas += [(s,s2)]\n",
    "        s,s2 = f\"err_sens ~ C({cocoln}) + {varn} + C({cocoln}) * {varn} + {varn} * prev_error_pscadj_abs\",\\\n",
    "            f\"1\"; flas += [(s,s2)]\n",
    "        s,s2 = f\"err_sens ~ C({cocoln}) + {varn} + C({cocoln}) * {varn}\", f\"~C({cocoln})\"; flas += [(s,s2)]\n",
    "        s,s2 = f\"err_sens ~ C({cocoln}) + {varn} + C({cocoln}) * {varn}\",\"1\";  flas += [(s,s2)]\n",
    "        \n",
    "        s,s2 = f\"err_sens ~ C({cocoln}) + {varn}\",f\"~C({cocoln})\"; flas += [(s,s2)]\n",
    "        s,s2 = f\"err_sens ~ C({cocoln}) + {varn}\",\"1\"; flas += [(s,s2)]        \n",
    "        \n",
    "     \n",
    "        results = {}\n",
    "        for s,s2 in flas:\n",
    "            try:                \n",
    "                model = smf.mixedlm(s, df_.copy(), \n",
    "                            groups=df_[\"subject\"], re_formula=s2)\n",
    "                with warnings.catch_warnings(record=True) as w:\n",
    "                    ###warnings.filterwarnings('ignore',category=ConvergenceWarning)     \n",
    "                    # n_jobs argument does not really work :(\n",
    "                    result = model.fit(n_jobs =n_jobs_inside)\n",
    "                    wmess = []\n",
    "                    for warning in w:\n",
    "                        wmess += [warning.message]\n",
    "                    result.converged2 = result.converged and \\\n",
    "                        ( not (result.params.isna().any() | result.pvalues.isna().any()) )\n",
    "                    result.wmess = wmess\n",
    "\n",
    "            except LinAlgError as le:\n",
    "                excfmt = traceback.format_exc()\n",
    "                result = None\n",
    "            results[(s,s2)] = result\n",
    "        \n",
    "    s2summary = {}\n",
    "    for stpl,result in results.items():        \n",
    "        if (result is not None) and result.converged:\n",
    "            #result.remove_data()\n",
    "            summary = result.summary()\n",
    "            summary.tables[0].loc[5,2] = 'Converged2:'\n",
    "            summary.tables[0].loc[5,3] = 'Yes' if result.converged2 else 'No'\n",
    "            summary.wmess = result.wmess\n",
    "            summary.params = result.params\n",
    "            summary.pvalues = result.pvalues\n",
    "        else:\n",
    "            summary = None\n",
    "        s2summary[stpl] = summary\n",
    "    print(args[1:])\n",
    "    r = {'cocoln': cocoln, 'histlen': std_mavsz_,\n",
    "            'varn': varn, 'varn0':varn0, 'varn_suffix':varn_suffix,             \n",
    "             'excfmt':excfmt,\n",
    "            's2summary': s2summary, 'retention_factor':df_.iloc[0]['retention_factor_s']}\n",
    "            #'res': result}\n",
    "            #'nstarts':nstarts,\n",
    "    if ret_res:\n",
    "        r['s2res'] = results\n",
    "    return r\n",
    "\n",
    "N = 25\n",
    "# Create args array using product\n",
    "cocols = ['None', 'env', 'ps2_']\n",
    "#cocols = [ 'env'] #, 'ps2_']\n",
    "#std_mavsz_range = range(2, 30)\n",
    "std_mavsz_range = list(range(3,N)) + list( range(N, 40, 3) )\n",
    "#std_mavsz_range = range(2, 20)\n",
    "#std_mavsz_range = range(2, 12)\n",
    "#std_mavsz_range = range(2, 3)\n",
    "varn0s = ['error_pscadj', 'error_pscadj_abs']\n",
    "#varn_suffixes = ['std', 'invstd', 'mavsq', 'mav_d_std', 'mav_d_var', 'Tan']\n",
    "varn_suffixes = all_suffixes\n",
    "\n",
    "# shorter\n",
    "cocols = [ 'env', 'ps2_']\n",
    "#varn0s = ['error'] #, 'error_pscadj', 'error_pscadj_abs']\n",
    "#varn_suffixes = ['std', 'invstd', 'Tan']\n",
    "#N_ = 10\n",
    "#std_mavsz_range = list(range(3,N_)) + list( range(N_, 32, 3) )\n",
    "\n",
    "# #std_mavsz_range = range(2, 15)\n",
    "# std_mavsz_range = range(2, 30)\n",
    "# varn0s = ['error_pscadj_abs']\n",
    "# #varn0s = ['error_pscadj', 'error_pscadj_abs']\n",
    "# #cocols = [ 'env', 'ps2_']\n",
    "# #cocols = [ 'ps2_']\n",
    "# cocols = [ 'env']\n",
    "\n",
    "args = list(product(cocols, std_mavsz_range, varn0s, varn_suffixes))\n",
    "print(len(args))\n",
    "# Number of processes\n",
    "#n_jobs = 10  # Use all available CPUs even with one job\n",
    "#n_jobs = 5\n",
    "n_jobs = 1\n",
    "\n",
    "ind = 0\n",
    "if n_jobs > 1:\n",
    "    # Execute in parallel\n",
    "    backend = 'multiprocessing' # 'loky'\n",
    "    #backend = 'loky' \n",
    "    prl = Parallel(n_jobs=n_jobs, backend = backend)\\\n",
    "        (delayed(run_model)( (dfcs_fixhistlen,*arg) ) for arg in args)\n",
    "else:\n",
    "    for arg in args:\n",
    "        prl += [run_model((dfcs_fixhistlen,*arg))]\n",
    "#     for arg in args[69:69+1]:\n",
    "#         prl += [run_model((dfcs_fixhistlen,*arg),ret_res=True)]\n",
    "        \n",
    "        if len(prl) >= 100:            \n",
    "            s_ = str(datetime.now())[:-7].replace(' ','_')\n",
    "            np.savez( pjoin(path_data, f'prl_{ind}_{s_}'), prl )\n",
    "            ind += 1\n",
    "            del prl\n",
    "            gc.collect()\n",
    "            prl = []\n",
    "    # to save the last\n",
    "    s_ = str(datetime.now())[:-7].replace(' ','_')\n",
    "    np.savez( pjoin(path_data, f'prl_{ind+1}_{s_}'), prl )\n",
    "\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f97b71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(args))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
