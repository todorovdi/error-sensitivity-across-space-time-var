{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e06c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /p/home/jusers/todorov3/jusuf/bmp_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672794b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "from datetime import datetime\n",
    "import pingouin as pg\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pingouin import ttest\n",
    "\n",
    "import pingouin as pg\n",
    "from joblib import Parallel, delayed\n",
    "from itertools import product\n",
    "import warnings\n",
    "\n",
    "from bmp_config import path_data, envcode2env\n",
    "from bmp_behav_proc import *\n",
    "load = 1\n",
    "if load:\n",
    "    fnf_fhl = pjoin(path_data,'dfcs_fixhistlen.pkl')\n",
    "    print(fnf_fhl)\n",
    "    print( str(datetime.fromtimestamp(os.stat(fnf_fhl).st_mtime)))\n",
    "    dfcs_fixhistlen = pd.read_pickle(fnf_fhl )\n",
    "else:\n",
    "    fnf = pjoin(path_data,'df_all_multi_tsz__.pkl.zip')\n",
    "    print(fnf)\n",
    "    print( str(datetime.fromtimestamp(os.stat(fnf).st_mtime)))\n",
    "    df_all_multi_tsz = pd.read_pickle(fnf)\n",
    "    df = df_all_multi_tsz.query('trial_shift_size == 1 and trial_group_col_calc == \"trialwe\" '\n",
    "                            ' and retention_factor_s == \"0.924\"').copy().sort_values(['subject','trials'])\n",
    "    df,dfall,ES_thr,envv,pert = addBehavCols2(df);\n",
    "    dfc = df.copy()\n",
    "    dfcs,dfcs_fixhistlen,dfcs_fixhistlen_untrunc,histlens  = addWindowStatCols(dfc, ES_thr, \n",
    "                                        varn0s = ['error','error_pscadj','error_pscadj_abs'])\n",
    "    dfcs_fixhistlen, me_pct_excl = truncLargeStats(dfcs_fixhistlen_untrunc, histlens, 5.)\n",
    "import pingouin as pg\n",
    "dfcs_fixhistlen['environment'] = dfcs_fixhistlen['environment'].astype(int)\n",
    "df_ = dfcs_fixhistlen[['environment','subject','trials','error_pscadj_abs_Tan29']]\n",
    "assert not df_.duplicated(['subject','trials']).any()\n",
    "all_suffixes = 'mav,std,invstd,mavsq,mav_d_std,mav_d_var,Tan,invmavsq,invmav,std_d_mav,invTan'.split(',')\n",
    "\n",
    "dfcs_fixhistlen0 = dfcs_fixhistlen.copy()\n",
    "print(len(dfcs_fixhistlen))\n",
    "c = ~  np.isinf(dfcs_fixhistlen['err_sens']) \n",
    "dfcs_fixhistlen = dfcs_fixhistlen.loc[c]\n",
    "print(len(dfcs_fixhistlen))\n",
    "c2 = dfcs_fixhistlen['err_sens'] > -41\n",
    "dfcs_fixhistlen = dfcs_fixhistlen.loc[c2]\n",
    "print(len(dfcs_fixhistlen))\n",
    "\n",
    "# make sure length n  is inside\n",
    "varn0 = 'error_pscadj'\n",
    "n = 3\n",
    "for suffix in all_suffixes:\n",
    "    s = f'{varn0}_{suffix}{n}'\n",
    "    if s not in dfcs_fixhistlen.columns:\n",
    "        print(s, 'not in dfcs_fixhistlen.columns')\n",
    "    assert s in dfcs_fixhistlen.columns\n",
    "\n",
    "print('all_suffixes = ', all_suffixes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prl_path_data = pjoin(path_data, '../NIH_behav_intermed_data', 'mixedlm_prl')\n",
    "fnf =  pjoin(prl_path_data, f'corrs_alltogether.pkl.zip') \n",
    "\n",
    "#fnf =  pjoin(prl_path_data, f'corrs_alltogether_noebm_3cond.pkl.zip') \n",
    "fnf_mesubj =  pjoin(prl_path_data, f'corrs_mesubj_alltogether.pkl.zip') \n",
    "\n",
    "load = 1\n",
    "if load:\n",
    "    cocoln2corrs_per_subj = pd.read_pickle(fnf)\n",
    "    print(str(datetime.fromtimestamp(os.stat(fnf).st_mtime)))\n",
    "    cocoln2corrs_mesubj = pd.read_pickle(fnf_mesubj)\n",
    "else:\n",
    "    print('Not loaded, need recalc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50fece3",
   "metadata": {},
   "source": [
    "# Recalc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad17be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_range = 3\n",
    "max_range = 40\n",
    "N = 41\n",
    "n_jobs = 256\n",
    "\n",
    "\n",
    "# max_range = 21\n",
    "# N = 21\n",
    "#n_jobs = 1\n",
    "# min_range = 20\n",
    "# max_range = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd19a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "from interpret import show\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "# if use shepherd, it is rather slow even in parallel mode\n",
    "#corr_methods = ['spearman','shepherd']\n",
    "corr_methods = ['spearman', 'pearson']\n",
    "\n",
    "#corr_methods = [ 'pearson']\n",
    "#cocols = ['None', 'env', 'ps2_']  # maybe I don't need ps2_ actually\n",
    "cocols = [ 'env']  # maybe I don't need ps2_ actually\n",
    "\n",
    "varn0s = ['error_pscadj', 'error_pscadj_abs']\n",
    "varn_suffixes = ['std', 'invstd', 'mavsq', 'mav_d_std', 'mav_d_var', 'Tan']\n",
    "\n",
    "std_mavsz_range = list(range(min_range, min(N, max_range)) )\n",
    "if N < max_range:\n",
    "    std_mavsz_range += list(range(N, max_range, 3))\n",
    "\n",
    "args = list(product(corr_methods, cocols, std_mavsz_range, varn0s, varn_suffixes))\n",
    "print(len(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2451cb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s2_ 22 error_pscadj_abs mav_d_std\n",
    "# ps2_ 22 error_pscadj_abs mav_d_var\n",
    "# ps2_ 23 error_pscadj std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95baba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute corrs within subject\n",
    "do_ebm = 1\n",
    "n_folds = 5\n",
    "#backend = 'loky'\n",
    "backend = 'multiprocessing' \n",
    "\n",
    "def run_corr(df_big, corr_method, cocoln, std_mavsz_, varn0, varn_suffix):\n",
    "    def f(df_):\n",
    "        with warnings.catch_warnings(record=True) as w:\n",
    "            warnings.filterwarnings('ignore',category=UserWarning)\n",
    "            warnings.filterwarnings('ignore',category=RuntimeWarning)\n",
    "\n",
    "            try:\n",
    "                r = pg.corr( df_[varn], df_['err_sens'],  method=corr_method)\n",
    "            except ValueError as e:\n",
    "                r = pd.DataFrame({'n': [len(df_)], 'r': [np.nan], 'p-val': [np.nan]})\n",
    "\n",
    "\n",
    "        r['method'] = corr_method\n",
    "        return r\n",
    "\n",
    "    def f_ebm(df_):\n",
    "        X_train = df_[varn].values.reshape(-1, 1) \n",
    "        y_train = df_['err_sens'].values#.reshape(-1, 1) \n",
    "        #print(X_train.shape, y_train.shape)\n",
    "        ebm = ExplainableBoostingRegressor(feature_names=[varn], random_state=42)\n",
    "        cv_scores = cross_val_score(ebm, X_train, y_train, cv=n_folds, scoring='r2')\n",
    "        #print(f\"Cross-validation R2 scores: {cv_scores}\")\n",
    "        r2 = np.mean(cv_scores)\n",
    "        print(f\"{varn} mean CV R2 score: {r2:.4f}\")\n",
    "        return r2\n",
    "    \n",
    "    #dfcs_fixhistlen, cocoln, std_mavsz_, varn0, varn_suffix = args\n",
    "    varn = f'{varn0}_{varn_suffix}{std_mavsz_}'\n",
    "    #cols = ['thr','subject']\n",
    "    cols = ['subject']\n",
    "    if cocoln != 'None':\n",
    "        cols += [cocoln]\n",
    "    assert not df_big.duplicated(cols + ['trials']).any()\n",
    "\n",
    "    df_ = df_big\n",
    "    df_ = df_[~np.isnan(df_[varn])] #NaN\n",
    "    df_ = df_[~np.isnan(df_[varn])]\n",
    "    df_ = df_[~np.isinf(df_[varn])]\n",
    "    df_ = df_[~np.isinf(-df_[varn])]\n",
    "    df_ = df_[~np.isinf(df_['err_sens'])]\n",
    "    df_ = df_[~np.isinf(-df_['err_sens'])]\n",
    "\n",
    "\n",
    "    g = df_.groupby(cols, observed=True)\n",
    "    corrs_per_subj = g.apply(f, include_groups=False)\n",
    "    corrs_per_subj = corrs_per_subj.rename(columns={'p-val':'pval'})\n",
    "\n",
    "    if do_ebm:\n",
    "        corrs_per_subj['R2_ebm'] = g.apply(f_ebm, include_groups=False)\n",
    "\n",
    "    corrs_per_subj['std_mavsz'] = std_mavsz_\n",
    "    corrs_per_subj['histlen'] = std_mavsz_\n",
    "    corrs_per_subj['varn'] = varn\n",
    "    corrs_per_subj['varn0'] = varn0\n",
    "    corrs_per_subj['cocoln'] = cocoln\n",
    "    corrs_per_subj['varn_suffix'] = varn_suffix\n",
    "\n",
    "    print(corr_method, cocoln, std_mavsz_, varn0, varn_suffix)\n",
    "    return corrs_per_subj.reset_index()\n",
    "\n",
    "ind = 0\n",
    "if n_jobs > 1:\n",
    "    # Execute in parallel\n",
    "    prlcorr = Parallel(n_jobs=n_jobs, backend = backend)\\\n",
    "        (delayed(run_corr)( dfcs_fixhistlen,*arg ) for arg in args)\n",
    "    \n",
    "else:\n",
    "    #raise ValueError('I\\'m lazy to implement')\n",
    "    prlcorr = []\n",
    "    for arg in args:\n",
    "        ind += 1\n",
    "        print(f'Running {ind}/{len(args)}')\n",
    "        res = run_corr(dfcs_fixhistlen, *arg)\n",
    "        prlcorr.append(res)\n",
    "cocoln2corrs_per_subj = pd.concat(prlcorr).reset_index()\n",
    "\n",
    "#coefficient of determination for the ranks if Spearman.\n",
    "cocoln2corrs_per_subj.loc[cocoln2corrs_per_subj['method'] == 'spearman','R2'] =\\\n",
    "     cocoln2corrs_per_subj['r']**2\n",
    "print('Calc finished well!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576245c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute corrs after average across subjects (pretty useless acutally) \n",
    "# env\n",
    "def run_corr_me(df_big, corr_method, cocoln, std_mavsz_, varn0, varn_suffix):\n",
    "    def f(df_):\n",
    "        with warnings.catch_warnings(record=True) as w:\n",
    "            warnings.filterwarnings('ignore',category=UserWarning)\n",
    "            warnings.filterwarnings('ignore',category=RuntimeWarning)\n",
    "\n",
    "            r = pg.corr( df_[varn], df_['err_sens'],  method=corr_method)\n",
    "        r['method'] = corr_method\n",
    "        return r\n",
    "    \n",
    "    varn = f'{varn0}_{varn_suffix}{std_mavsz_}'\n",
    "    cols_av = ['trials']\n",
    "    cols = []\n",
    "    if cocoln != 'None':\n",
    "        cols += [cocoln]\n",
    "    cols_keep = cols_av + cols + ['err_sens',varn]\n",
    "\n",
    "    df_ = df_big\n",
    "    df_ = df_[~np.isnan(df_[varn])] #NaN\n",
    "    df_ = df_[~np.isinf(df_[varn])]\n",
    "    df_ = df_[~np.isinf(-df_[varn])]\n",
    "    df_ = df_[~np.isinf(df_['err_sens'])]\n",
    "    df_ = df_[~np.isinf(-df_['err_sens'])]\n",
    "\n",
    "    dfcs_fixhistlen_me = df_[cols_keep].\\\n",
    "        groupby(cols_av + cols, observed=True).mean().reset_index()\n",
    "    assert not dfcs_fixhistlen_me.duplicated(cols + ['trials']).any()                \n",
    "\n",
    "\n",
    "    if len(cols) == 0:\n",
    "        corrs_mesubj = f(dfcs_fixhistlen_me)\n",
    "    else:\n",
    "        corrs_mesubj = dfcs_fixhistlen_me.groupby(cols, \n",
    "            observed=True).apply(f, include_groups=False)\n",
    "    corrs_mesubj = corrs_mesubj.rename(columns={'p-val':'pval'})\n",
    "    corrs_mesubj['varn'] = varn\n",
    "    corrs_mesubj['varn0'] = varn0\n",
    "    corrs_mesubj['cocoln'] = cocoln\n",
    "    corrs_mesubj['std_mavsz'] = std_mavsz_\n",
    "    corrs_mesubj['histlen'] = std_mavsz_\n",
    "    corrs_mesubj['varn_suffix'] = varn_suffix\n",
    "\n",
    "    print(cocoln, std_mavsz_, varn0, varn_suffix)\n",
    "    return corrs_mesubj.reset_index()\n",
    "\n",
    "ind = 0\n",
    "if n_jobs > 1:\n",
    "    # Execute in parallel\n",
    "    #backend = 'multiprocessing' # 'loky'\n",
    "    backend = 'multiprocessing' \n",
    "    prlcorr = Parallel(n_jobs=n_jobs, backend = backend)\\\n",
    "        (delayed(run_corr_me)( dfcs_fixhistlen,*arg ) for arg in args)\n",
    "\n",
    "else:\n",
    "    #raise ValueError('I\\'m lazy to implement')\n",
    "    prlcorr = []\n",
    "    for arg in args:\n",
    "        ind += 1\n",
    "        print(f'Running {ind}/{len(args)}')\n",
    "        res = run_corr_me(dfcs_fixhistlen, *arg)\n",
    "        prlcorr.append(res)\n",
    "cocoln2corrs_mesubj = pd.concat(prlcorr).reset_index()\n",
    "print('Calc finished well!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992a0f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0f8c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7726b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cocoln2corrs_per_subj.to_pickle(fnf)\n",
    "cocoln2corrs_mesubj.to_pickle(fnf_mesubj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12462c11",
   "metadata": {},
   "source": [
    "# Analyze: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e9e717",
   "metadata": {},
   "source": [
    "## Corr for all without regard for env/ps2_ (pooled trials, not used now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2678170e",
   "metadata": {},
   "source": [
    "###  all trials together, mean across subjects (useless actually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56a4960",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrs_pos = cocoln2corrs_mesubj.query('cocoln == \"None\" and pval <= 0.05 and r > 0')\n",
    "varnames = list(ttrs_pos.reset_index()['varn'].values)\n",
    "print(varnames )\n",
    "print('For mean,then corr {} varnames are >0 correlated'.format(len(varnames) ) )\n",
    "ttrs_pos[['varn','pval','r','power']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8edb8a",
   "metadata": {},
   "source": [
    "### all trial together, per subj "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8720c481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# want statistically significant correlations (so look at sets per subject)\n",
    "def f(df):\n",
    "    if len(df) == 0:\n",
    "        return None\n",
    "    ttrs = compare0(df, 'r', cols_addstat=['r'])\n",
    "    return ttrs\n",
    "m2vns={}\n",
    "\n",
    "# include groups is whether df that f receives as arg has grouping columns or not\n",
    "g = cocoln2corrs_per_subj.query('cocoln == \"None\"').\\\n",
    "    groupby(['varn','varn0','varn_suffix','method','histlen'], observed=True)\n",
    "print(g.size().max())\n",
    "ttrs = g.apply(f, include_groups=False)\n",
    "\n",
    "#display(ttrs.query('pval <= 0.05 and ttstr == \"r < 0\"')\\\n",
    "#        [['pval','ttstr']])\n",
    "\n",
    "ttrs_pos = ttrs.query('histlen > 3 and pval <= 0.05 and ttstr == \"r > 0\"')\n",
    "#display(ttrs_pos[['pval','ttstr']])\n",
    "for method in cocoln2corrs_per_subj.method.unique():\n",
    "    varnames = ttrs_pos.loc[ttrs_pos.index.get_level_values('method') == method].\\\n",
    "        reset_index()['varn'].values\n",
    "    varnames = list(varnames)\n",
    "    #varnames = list(ttrs_pos[(None,method)])\n",
    "    #print(varnames )\n",
    "    print(method, len(varnames), ' varnames are >0 correlated' )\n",
    "    m2vns[method] = varnames\n",
    "\n",
    "#print( ', '.join(varnames) )\n",
    "#print ('Dif between methods ',set(m2vns['spearman']) ^ set(m2vns['shepherd']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babaa47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrs_pos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c162b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Romain goes maybe in sept 2026 to Japan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d707bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "histlens_sigpos = ttrs_pos.reset_index().groupby(['method','varn0','varn_suffix'])['histlen'].unique().to_frame()\n",
    "#histlens_sigpos\n",
    "for irow,row in histlens_sigpos.iterrows():\n",
    "    m, varn0, varn_suffix = row.name\n",
    "    histlens = row['histlen']\n",
    "    from bmp_base import find_continuous_streaks\n",
    "    streaks = find_continuous_streaks(sorted(histlens))\n",
    "    #m = row.menthod\n",
    "    #hls = \",\".join(map(str,sorted(histlens)))\n",
    "    print(f'{m}: {varn0}_{varn_suffix:9}, histlens={streaks}')\n",
    "    # if len(histlens) == 1:\n",
    "    #     print(f'Only one histlen {histlens[0]}')\n",
    "    # else:\n",
    "    #     print(f'Multiple histlens {histlens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732a790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ttrs_pos = ttrs_pos.query('method == \"spearman\"')\n",
    "ttrs_pos = ttrs.query('histlen > 3 and pval <= 0.05 and ttstr == \"r > 0\"')\n",
    "ttrs_pos = ttrs_pos.query('method == \"pearson\"')\n",
    "ttrs_pos = ttrs_pos.sort_values(['pval'])\n",
    "ttrs_pos[['pval','power','r_mean','r_std','T']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcd2113",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrs_pos = ttrs_pos.query('method == \"spearman\"')\n",
    "ttrs_pos = ttrs.query('histlen > 3 and pval <= 0.05 and ttstr == \"r > 0\"')\n",
    "#ttrs_pos = ttrs_pos.query('method == \"pearson\"')\n",
    "ttrs_pos = ttrs_pos.sort_values(['pval'])\n",
    "ttrs_pos[['pval','power','r_mean','r_std','T']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c3f722",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ttrs_pos.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186eaf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrs_pos_ = ttrs_pos.reset_index().\\\n",
    "    query('method == \"spearman\" and varn_suffix == \"Tan\" and varn0 == \"error_pscadj_abs\"')\n",
    "\n",
    "display(ttrs_pos_[['histlen','pval','power','r_mean','r_std']])\n",
    "print(find_continuous_streaks(ttrs_pos_['histlen'].values))\n",
    "print(ttrs_pos_['histlen'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2af92fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae29ddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrs_pos = ttrs_pos.query('varn.str.contains(\"_invstd\")').sort_values(['r_mean'], ascending=False)\n",
    "ttrs_pos[['pval','T','r_mean','r_std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8472e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ttrs_pos.query('varn.str.endswith(\"std2\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b1400",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ = pd.DataFrame( {'varn':m2vns['spearman'] } )\n",
    "#df_['']\n",
    "\n",
    "# std2\n",
    "# invstd 4-39\n",
    "# abs invstd 2-39\n",
    "# abs mav d var 4-39\n",
    "\n",
    "m2vns['spearman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662a05ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ES vs windows stats\n",
    "import warnings\n",
    "varnames = list(ttrs_pos.reset_index()['varn'].values)\n",
    "if len(varnames) <= 10:\n",
    "    print(varnames)\n",
    "    for env in ['stable','random']:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "            me = dfcs_fixhistlen.query('env == @env').\\\n",
    "                groupby(['subject','env'])[['err_sens']+varnames].mean().reset_index()\n",
    "            fg = sns.pairplot(data=me, \n",
    "                     y_vars = ['err_sens'], hue='env',\n",
    "                         x_vars=['err_sens'] + varnames)#,corner=1)\n",
    "\n",
    "    me = dfcs_fixhistlen.\\\n",
    "        groupby(['subject'])[['err_sens']+varnames].mean().reset_index()\n",
    "    fg = sns.pairplot(data=me, \n",
    "             y_vars = ['err_sens'], \n",
    "                 x_vars=['err_sens'] + varnames)#,corner=1)\n",
    "else:\n",
    "    print('Too long list of varnames ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963563bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ec2a5",
   "metadata": {},
   "source": [
    "## Corr within env (of ES and windows-stat measues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd65dec3",
   "metadata": {},
   "source": [
    "\n",
    "### mesubj (useless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e0b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it gives 0 because for random it does not make sense to average across participants\n",
    "# because randomness is not consistent across them\n",
    "env2varnames = {}\n",
    "ttrs = cocoln2corrs_mesubj['env']\n",
    "for env in ['stable','random']:\n",
    "    ttrs_pos = ttrs.query('pval <= 0.05 and r > 0 and'\n",
    "                         ' env == @env')\n",
    "#display(ttrs_pos[['pval','ttstr']])\n",
    "    varnames = list(ttrs_pos.reset_index()['varn'].values)\n",
    "    print(env,len(varnames))\n",
    "    env2varnames[env] = varnames\n",
    "varnames_isec = set(env2varnames['stable']) & set(env2varnames['random'])\n",
    "varnames_isec = list(varnames_isec)\n",
    "print('random ', set(env2varnames['random']))\n",
    "print('isec varnames',varnames_isec  )\n",
    "\n",
    "print('For mean, stable&random corr {} varnames are >0 correlated'.format(len(varnames) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b449c0ca",
   "metadata": {},
   "source": [
    "### within subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11fe1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find with windows stats are positive bot for random AND for stable\n",
    "#from behav_proc import compare0\n",
    "def f(df):\n",
    "    if len(df) == 0:\n",
    "        return None\n",
    "    ttrs_ = compare0(df, 'r')\n",
    "    return ttrs_\n",
    "\n",
    "ttrs = cocoln2corrs_per_subj.query('cocoln == \"env\"').\\\n",
    "    groupby(['method','varn','env','varn0','varn_suffix','histlen'], observed=True).apply(f)\n",
    "print('Calc finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0855138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Tan 20\n",
    "#coln_to_analyze = 'error_pscadj_abs_Tan20'\n",
    "coln_to_analyze = 'error_pscadj_Tan20'\n",
    "ttrs.query('varn == @coln_to_analyze')#.sort_values(['pval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7471736",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All positive, both envs (separately)')\n",
    "best = {}\n",
    "for method in cocoln2corrs_per_subj.method.unique():\n",
    "    #print(getAddInfo())\n",
    "    #display(ttrs.query('pval <= 0.05 and thr in @thrs')\\\n",
    "    #        [['pval','ttstr']])\n",
    "\n",
    "    ttrs_pos = ttrs.query('method == @method and pval <= 0.05 and ttstr == \"r > 0\"')\n",
    "    #display(ttrs_pos[['pval','ttstr']])\n",
    "\n",
    "    env2varnames = {}\n",
    "    for env in ['stable','random']:\n",
    "        ttrs_pos = ttrs.query('pval <= 0.05 and ttstr == \"r > 0\" and'\n",
    "                             ' env == @env').sort_values(['pval']).reset_index()\n",
    "        print(method, env) \n",
    "        bestrow = ttrs_pos.iloc[0]\n",
    "        best[(method,env)] = bestrow\n",
    "        display('best row = ',bestrow) \n",
    "        varn_ = bestrow.varn\n",
    "        persubj = cocoln2corrs_per_subj.query('method == @method and env == @env and varn == @varn_')\n",
    "        if method == 'spearman':\n",
    "            display(persubj[['subject','R2','R2_ebm']].describe(percentiles=[ .5]) )\n",
    "        elif method == 'pearson':\n",
    "            display(persubj[['subject','r','R2_ebm']].describe(percentiles=[ .5]) )\n",
    "\n",
    "    #display(ttrs_pos[['pval','ttstr']])\n",
    "        varnames = list(ttrs_pos['varn'].values)\n",
    "        env2varnames[env] = varnames\n",
    "    varnames_isec = set(env2varnames['stable']) & set(env2varnames['random'])\n",
    "    varnames_isec = list(varnames_isec)\n",
    "    print(method, 'isec varnames',varnames_isec  )\n",
    "#print(varnames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceb1614",
   "metadata": {},
   "source": [
    "### EBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8e8f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestrow = best[('spearman','stable')]\n",
    "print(bestrow)\n",
    "\n",
    "from bmp_base import calc_EBM\n",
    "ebm,cv_scores,r2 = calc_EBM(dfcs_fixhistlen.query('subject_ind == 1'), bestrow['histlen'], \n",
    "                            bestrow['varn0'], bestrow['varn_suffix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f8df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from interpret import show\n",
    "global_expl = ebm.explain_global()\n",
    "print(cv_scores,r2)\n",
    "show(global_expl)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7980af",
   "metadata": {},
   "outputs": [],
   "source": [
    "env2varnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a719cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be put into paper\n",
    "mer = cocoln2corrs_per_subj.query('cocoln == \"env\"').\\\n",
    "    groupby(['varn','env'], observed=True)['r'].mean()\n",
    "\n",
    "#print(getAddInfo(),'\\n')\n",
    "r = ttrs.query('pval <= 0.05 and ttstr == \"r > 0\" '\n",
    "    ' and varn.isin(@varnames_isec)').reset_index()[['varn','env','pval']].set_index(['varn','env'])\n",
    "#d = r.T.to_dict()\n",
    "#print(d)\n",
    "\n",
    "if r.empty:\n",
    "    print('no significant correlations in stable and random separately found')\n",
    "for varn in varnames_isec:\n",
    "    st = r.loc[(varn,'stable'),'pval']\n",
    "    ra = r.loc[(varn,'random'),'pval']\n",
    "    stabr = mer[(varn,'stable')]\n",
    "    randr = mer[(varn,'random')]\n",
    "    \n",
    "    s = (f\"{varn}: For random r>0 has p-val={ra:.2e} (mean r = {randr:.3f})\"\n",
    "        f\" and for stable r>0 has p-val={st:.2e} (mean r = {stabr:.3f})\")\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f2ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "h=4\n",
    "varnames_toshow = varnames_isec[1:]\n",
    "fg,df = relplot_multi(sep_ys_by = 'col', data=dfcs_fixhistlen, x='err_sens',ys=varnames_toshow, row='env',\n",
    "                     height = h)\n",
    "for ax in fg.axes.flatten():\n",
    "    ttl = ax.get_title().replace('__varname = ','').replace('env = ','')\n",
    "    ax.set_title(ttl)\n",
    "\n",
    "fg.refline(x=0)\n",
    "fg.refline(y=0)\n",
    "fg.fig.suptitle('Pooled')\n",
    "plt.tight_layout()\n",
    "\n",
    "me = dfcs_fixhistlen.\\\n",
    "    groupby(['subject','env'])[['err_sens']+varnames_toshow].mean().reset_index()\n",
    "fg,df = relplot_multi(sep_ys_by = 'col', data=me, x='err_sens',ys=varnames_toshow, row='env',\n",
    "                     height = h)\n",
    "for ax in fg.axes.flatten():\n",
    "    ttl = ax.get_title().replace('__varname = ','').replace('env = ','')\n",
    "    ax.set_title(ttl)\n",
    "fg.refline(x=0)\n",
    "fg.refline(y=0)\n",
    "fg.fig.suptitle('Mean within subject')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aced080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fg = sns.relplot(data=dfcs_fixhistlen, col='subject',\n",
    "#     y = 'err_sens', x=varnames_isec[0], row='env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8154bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from behav_proc import formatRecentStatVarnames\n",
    "isec_nice = formatRecentStatVarnames(varnames_isec)\n",
    "display(isec_nice)\n",
    "print('; '.join(isec_nice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e9765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "isec = set(env2varnames['stable']) & set(env2varnames['random'])\n",
    "if len(isec):\n",
    "    print('If we fix the history length first, then compute correlation '\n",
    "      'within participant (separately for both environments)'\n",
    "      ' and then choose variables for which r>0 stat significantly in both environments'\n",
    "      ' simultaneously, we get ',', '.join(list(isec) ) )\n",
    "else:\n",
    "    print('We get nothing signif postive in both separately')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727dd638",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ttrs.query('varn == \"error_pscadj_invstd10\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba2c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "varnames = list(ttrs_pos.reset_index()['varn'].values)\n",
    "print(varnames)\n",
    "for env in ['stable','random']:\n",
    "    plt.figure()\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "        fg = sns.pairplot(data=dfcs.query('env == @env').\\\n",
    "            groupby(['subject','env'])[['err_sens']+env2varnames[env]].mean().reset_index(), \n",
    "            y_vars = ['err_sens'], hue='env',\n",
    "            x_vars=['err_sens'] + env2varnames[env])#,corner=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f476b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You are an expert in python pandas and data science.\n",
    "# I have a pandas dataframe with the following columns\n",
    "# ttrs_pos.columns = ['alt', 'val1', 'ttstr','varn','env']\n",
    "# 'ttstr' can take two possible string values '>0' and '<0'. \n",
    "# 'env' can take two string values 'stable' and 'random'. \n",
    "# 'varn' can take several possible string values.\n",
    "# I want to select rows that have ttstr = '>0' for both stable and random values of 'env'.\n",
    "# How to do it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed59c97",
   "metadata": {},
   "source": [
    "## Corr within ps2_ (of ES and windows-stat measues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be4261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PS_\n",
    "# all corrs are positive within participants\n",
    "from behav_proc import compare0\n",
    "def f(df):\n",
    "    if len(df) == 0:\n",
    "        return None\n",
    "    ttrs = compare0(df, 'r')\n",
    "    return ttrs\n",
    "ttrs = cocoln2corrs_per_subj.query('cocoln == \"ps2_\"').\\\n",
    "    groupby(['varn','ps2_'], observed=True).apply(f)\n",
    "print(getAddInfo())\n",
    "ttrssig = ttrs.query('pval <= 0.05')\n",
    "#display(ttrssig[['pval','ttstr','T']])\n",
    "\n",
    "ttrs_pos = ttrs.query('pval <= 0.05 and ttstr == \"r > 0\"')\n",
    "display(ttrs_pos[['pval','ttstr']])\n",
    "varnames = list(ttrs_pos.reset_index()['varn'].values)\n",
    "print(varnames)\n",
    "#loc[:,'error_pscadj_std5',:]\n",
    "\n",
    "# ttrs = corrs_per_subj2.\\\n",
    "#     groupby(['thr','ps_']).apply(f)\n",
    "# print(getAddInfo())\n",
    "# display(ttrs.query('pval <= 0.05 and thr in @thrs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bf9185",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_v = dfall.reset_index()['ps2_'].unique()\n",
    "len(ps_v), ps_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea80161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of significant phases\n",
    "nu = ttrs_pos.reset_index().groupby(['varn'])[['ttstr','ps2_']].nunique()\n",
    "nu = nu.reset_index()\n",
    "display(nu[nu['ps2_'] > 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a4a1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "varns_good = nu[nu['ps2_'] == len(ps_v)].varn.values\n",
    "print(varns_good)\n",
    "\n",
    "varns_pre_good = nu[nu['ps2_'] == len(ps_v)-1].varn.values\n",
    "print(varns_pre_good)\n",
    "\n",
    "from behav_proc import formatRecentStatVarnames\n",
    "isec_nice = formatRecentStatVarnames(varns_good)\n",
    "display(varns_good)\n",
    "print('; '.join(isec_nice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3270619",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrs_pos.query('varn.isin(@varns_pre_good)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a17bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrssig_g = ttrssig_pos.reset_index().query('varn in @varns_good')\\\n",
    "    [['varn','ps_','pval','ttstr']]\n",
    "display(ttrssig_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20b590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mer = cocoln2corrs_per_subj.query('cocoln == \"ps2_\"').\\\n",
    "    groupby(['varn','ps2_'], observed=True)['r'].mean()\n",
    "\n",
    "for varn in varns_good:\n",
    "    print('  ',varn)    \n",
    "    \n",
    "    r = ttrssig_g.query('varn == @varn').\\\n",
    "        reset_index()[['varn','ps2_','pval']]\n",
    "    d = r.T.to_dict()\n",
    "    #print(d)\n",
    "    s = ''\n",
    "    for k,v in d.items(): \n",
    "        ps_nice = ps_2nice[v['ps2_']].lower()\n",
    "        fv = v['pval']\n",
    "        s += f\"for {ps_nice} \"            \n",
    "        s += f' mean r = {mer[(varn,v[\"ps2_\"])]:.3f} and p-val={fv:.3e}; '        \n",
    "            \n",
    "        \n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca88d9cf",
   "metadata": {},
   "source": [
    "## Histlen individ per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d09786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfcs_multi\n",
    "# good to add block name because we make a pause between so supposedly we loose memory about last errors\n",
    "dfcs2 = dfc.sort_values(\n",
    "    ['pert_seq_code', 'subject', 'trial_group_col_calc','trials'])\n",
    "grp = dfcs2.\\\n",
    "    groupby(['pert_seq_code', 'subject', 'trial_group_col_calc','block_name'],\n",
    "           observed=True)\n",
    "\n",
    "vars_to_av = ['error_pscadj', 'error_pscadj_abs'] \n",
    "\n",
    "dfs = []\n",
    "#for std_mavsz_ in range(2,4):\n",
    "for std_mavsz_ in range(2,30):    \n",
    "    print(std_mavsz_)\n",
    "    df_ = dfcs2.copy()\n",
    "    df_['histlen'] = std_mavsz_\n",
    "    for varn in vars_to_av:\n",
    "        for g,gi in grp.groups.items():\n",
    "            df_.loc[gi,f'{varn}_std'] = df_.loc[gi,varn].shift(1).rolling(std_mavsz_).std()   \n",
    "            df_.loc[gi,f'{varn}_mav'] = df_.loc[gi,varn].shift(1).rolling(std_mavsz_).mean()   \n",
    "                \n",
    "        df_[f'{varn}_invstd'] = 1/df_[f'{varn}_std']\n",
    "        df_[f'{varn}_var']    = df_[f'{varn}_std'] ** 2\n",
    "        df_[f'{varn}_mavsq']  = df_[f'{varn}_mav'] ** 2\n",
    "        df_[f'{varn}_mav_d_std']  = df_[f'{varn}_mav'].abs() / df_[f'{varn}_std']\n",
    "        df_[f'{varn}_mav_d_var']  = df_[f'{varn}_mav'].abs() / df_[f'{varn}_var']\n",
    "        df_[f'{varn}_Tan']    = df_[f'{varn}_mavsq'] / df_[f'{varn}_var']\n",
    "    dfs += [df_]        \n",
    "dfcs0 = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# only chose points where prev error is not too small (to compare with ES later)\n",
    "dfcs_multi  = truncateDf(dfcs0, 'err_sens', q=0.0, infnan_handling='discard', \n",
    "                   cols_uniqify = ['subject','histlen']) #'env','thr',\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682c56bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute corrs\n",
    "from behav_proc import compare0\n",
    "# env\n",
    "# here dfcs_multi varnames don't contain histlen, it is a sep column\n",
    "histlens = dfcs_multi['histlen'].unique()\n",
    "dfs = []\n",
    "import pingouin as pg\n",
    "for cocoln in ['None', 'env']:#,'ps_']:\n",
    "    #for std_mavsz_ in histlens:    \n",
    "    for varn0 in ['error_pscadj','error_pscadj_abs']:\n",
    "        for varn in  [f'{varn0}_std',\n",
    "                      f'{varn0}_invstd',                     \n",
    "                     f'{varn0}_mavsq',\n",
    "                      f'{varn0}_mav_d_std',\n",
    "                      f'{varn0}_mav_d_var',\n",
    "                     f'{varn0}_Tan']:            \n",
    "            def f(df_):\n",
    "                r = pg.corr( df_[varn], df_['err_sens'],  method='spearman')\n",
    "                r['method'] = 'spearman'\n",
    "                return r\n",
    "            cols = ['histlen','subject']\n",
    "            if cocoln != 'None':\n",
    "                cols += [cocoln]\n",
    "            print('Starting ' ,cocoln, varn, cols)\n",
    "            assert not dfcs_multi.duplicated(cols + ['trials']).any()\n",
    "            corrs_per_subj = dfcs_multi.groupby(cols, observed=True).apply(f)\n",
    "            corrs_per_subj = corrs_per_subj.rename(columns={'p-val':'pval'})            \n",
    "            corrs_per_subj['varn'] = varn                    \n",
    "            corrs_per_subj['cocoln'] = cocoln #corrs_per_subj \n",
    "            dfs += [corrs_per_subj.reset_index()]\n",
    "    \n",
    "cocoln2corrs_per_subj_multi = pd.concat(dfs, ignore_index = True)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d943e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cocoln2corrs_per_subj_multi),len(cocoln2corrs_per_subj_.query('cocoln.isin([\"None\",\"env\"])'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f203ba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from behav_proc import formatRecentStatVarnames\n",
    "def printNice(ttrs):\n",
    "    for rowi,row in ttrs.iterrows():\n",
    "        varn = row['varn']\n",
    "        varn_nice = formatRecentStatVarnames([varn],'')[0]\n",
    "        s = varn_nice\n",
    "        s += f\" (history length mean={row['histlen_mean']:.1f} trials, std={row['histlen_std']:.1f} trials)\"\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad6df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(df):\n",
    "    if len(df) == 0:\n",
    "        return None\n",
    "    ttrs = compare0(df, 'r', cols_addstat = ['histlen'])\n",
    "    return ttrs\n",
    "\n",
    "for cocoln in ['None', 'env']: #,'ps_']:\n",
    "    # within env or not?\n",
    "    print('###### cocoln = ',cocoln)\n",
    "    \n",
    "    # choose best p-value among different histlens\n",
    "    if cocoln != 'None':\n",
    "        cocoln_add = [cocoln]\n",
    "    else:\n",
    "        cocoln_add = []    \n",
    "    df_ = cocoln2corrs_per_subj_multi.query('cocoln == @cocoln')\n",
    "    cols0 = ['subject','varn']    \n",
    "    cols0 += cocoln_add\n",
    "    grp = df_.groupby(cols0, observed=True )\n",
    "    \n",
    "    # take with with the lower p-value among all histlens\n",
    "    dfr = aggRows(df_, 'pval', 'min',  grp, coltake = 'corresp') \n",
    "    \n",
    "    display('r info:', dfr.\\\n",
    "        groupby(cocoln_add + ['varn'], observed=True)['r'].describe() )\n",
    "    display('(for r>0) histlen info:', \n",
    "        dfr.query('r > 0').groupby(cocoln_add + ['varn'], \n",
    "                                   observed=True)['histlen'].describe() )\n",
    "    display('(for r>0) pval info:', \n",
    "        dfr.query('r > 0').groupby(cocoln_add + ['varn'], \n",
    "                                   observed=True)['pval'].describe() )\n",
    "    # compare r with zero\n",
    "    cols1 = ['varn']\n",
    "    cols1 += cocoln_add\n",
    "    ttrs = dfr.\\\n",
    "        groupby(cols1, observed=True).apply(f).reset_index()\n",
    "    print(getAddInfo())\n",
    "    \n",
    "    cols = ['varn','pval','ttstr','histlen_mean','histlen_std']\n",
    "    cols = cocoln_add + cols\n",
    "    \n",
    "    ttrs_neg= ttrs.query('pval <= 0.05 and ttstr == \"r < 0\"')        \n",
    "    ttrs_pos = ttrs.query('pval <= 0.05 and ttstr == \"r > 0\"')   \n",
    "    display(ttrs_neg[cols])\n",
    "    display(ttrs_pos[cols])\n",
    "    \n",
    "    varnames = list(ttrs_pos.reset_index()['varn'].values)    \n",
    "    if cocoln != 'None':\n",
    "        varnames_ext = zip(varnames, list(ttrs_pos.reset_index()[cocoln].values) )\n",
    "        varnames_ext  = list(varnames_ext)\n",
    "        print('r>0 varnames ',varnames_ext)\n",
    "    else:\n",
    "        print('r>0 varnames' , ', '.join(varnames) )\n",
    "    \n",
    "    printNice(ttrs_pos)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "error-sensitivity-across-space-time-var",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
