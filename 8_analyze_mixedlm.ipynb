{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0ecd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "from bmp_config import path_data,envcode2env\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from bmp_behav_proc import *\n",
    "\n",
    "import numpy as np\n",
    "from pingouin import ttest\n",
    "from bmp_base import radius_cursor\n",
    "from datetime import datetime\n",
    "import bmp_behav_proc\n",
    "fnf_fhl = pjoin(path_data,'dfcs_fixhistlen.pkl')\n",
    "print(fnf_fhl)\n",
    "print( str(datetime.fromtimestamp(os.stat(fnf_fhl).st_mtime)))\n",
    "dfcs_fixhistlen = pd.read_pickle(fnf_fhl )\n",
    "dfcs_fixhistlen['environment'] = dfcs_fixhistlen['environment'].astype(int)\n",
    "df_ = dfcs_fixhistlen[['environment','subject','trials','error_pscadj_abs_Tan29']]\n",
    "assert not df_.duplicated(['subject','trials']).any()\n",
    "\n",
    "# load files with computed mixedlm results (prl* files)\n",
    "from datetime import datetime\n",
    "import dateutil, re\n",
    "import glob\n",
    "dtstart = dateutil.parser.parse('april 12 2024  01:00')\n",
    "\n",
    "prl_path_data = pjoin(path_data, '../NIH_behav_intermed_data', 'mixedlm_prl')\n",
    "\n",
    "\n",
    "prls_fnf = glob.glob(prl_path_data + '/prl_*_2025*')\n",
    "prl = []\n",
    "for p in prls_fnf:    \n",
    "    #p=  pjoin(path_data, f'prl_{ind}.npz')\n",
    "    if not os.path.exists(p):\n",
    "        continue\n",
    "\n",
    "    print(p)\n",
    "    match = 1\n",
    "    #match = pattern.match(os.path.basename(p) )\n",
    "    if match:            \n",
    "        dt = datetime.fromtimestamp(os.path.getmtime(p))\n",
    "        if not dt >= dtstart:\n",
    "            continue    \n",
    "        print('  ',p, dt)\n",
    "        prl_ = np.load(p,allow_pickle=1)['arr_0']\n",
    "        print(len(prl_))\n",
    "        for item in prl_:\n",
    "            item['dt'] = dt\n",
    "        #prl__ = [(dt,_item) for _item in prl_]\n",
    "        prl += list(prl_)\n",
    "\n",
    "print('Total len ',len(prl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a6512f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# READ: extract stuff from prl (the precomputed mixed linear model fits)\n",
    "import re\n",
    "def cnv(s):\n",
    "    v = np.nan\n",
    "    if s != '':\n",
    "        v = float(s)\n",
    "    return v\n",
    "\n",
    "regex = re.compile(r'C\\([a-zA-Z2_]+\\)\\[T\\.([a-zA-Z_]+)\\]$')\n",
    "#DEBUG = 1\n",
    "DEBUG = 0\n",
    "clean_summary = 1 # if True, then remove fittedvalues and resid from summary\n",
    "ind = 0  # for counting only\n",
    "mixmr = []\n",
    "for ip,p in enumerate(prl):\n",
    "#for ip,p in enumerate(prl[136:136+1]):        \n",
    "    dd_ = p.copy()\n",
    "    dd_['ind_in_prl'] = ip\n",
    "    #del dd_['s']    \n",
    "    \n",
    "    varn = dd_['varn']\n",
    "    s2summ = dd_['s2summary']\n",
    "    #transform = dd_['transform']\n",
    "    \n",
    "    for (s,scov),summ in s2summ.items():                \n",
    "        if summ is None:\n",
    "            dd_['converged'] = False\n",
    "            print('skipping due to non-convergence ',s,scov)\n",
    "            continue        \n",
    "        dd = {}\n",
    "        dd['s'] = s\n",
    "        dd['scov'] = scov\n",
    "\n",
    "        dd.update(dd_)        \n",
    "        dd = dd.copy()\n",
    "\n",
    "        dd['transform'] = dd_['transform']\n",
    "\n",
    "        co = dd['cocoln']\n",
    "        if co == 'env':\n",
    "            dd['refcond'] = 'random'\n",
    "        else:\n",
    "            dd['refcond'] = 'pert'\n",
    "        \n",
    "        del dd['s2summary'] # because we need only one\n",
    "            \n",
    "        tab = summ.tables[0]\n",
    "        converged  = tab.loc[4,3] == 'Yes'\n",
    "        converged2 = tab.loc[5,3] == 'Yes'\n",
    "\n",
    "        fet = summ.tables[1].rename(columns={'P>|z|':'pval', 'Coef.':'coef'} )    \n",
    "\n",
    "        fet.pval = fet.pval.apply(cnv)\n",
    "        fet.coef = fet.coef.apply(cnv)\n",
    "        fet['pval_full'] = summ.pvalues.to_frame()[0] # because in tables[1] precision is cut to 2 floating points\n",
    "        fet['coef_full'] = summ.params.to_frame()[0] # because in tables[1] precision is cut to 2 floating points\n",
    "        fet0 = fet.reset_index()        \n",
    "        \n",
    "        dd['fet0'] = fet0\n",
    "\n",
    "        #fet0 = row['fet0'].set_index('index')\n",
    "        \n",
    "        \n",
    "        def f(row):\n",
    "            # Find all occurrences between [T. and ]\n",
    "            s = row['index']\n",
    "            match = re.findall(r\"\\[T\\.([^\\]]*)\\]\", s)\n",
    "            if match:\n",
    "                return match[0]\n",
    "            else:\n",
    "                return dd['refcond']\n",
    "        fet0['cond'] = fet0.apply(f,1)\n",
    "\n",
    "        d = fet[['pval','coef']].T.to_dict()\n",
    "        dd['intercept_pval'] = summ.pvalues['Intercept'] #d['Intercept']['pval']\n",
    "        dd['intercept_coef'] = summ.params['Intercept'] #d['Intercept']['coef']\n",
    "                \n",
    "        dd['varn_coef'] = summ.params[varn] #d[varn]['coef'] # main effect\n",
    "        dd['varn_pval'] = summ.pvalues[varn] #d[varn]['pval']\n",
    "        dd['converged']  = converged\n",
    "        dd['converged2'] = converged2\n",
    "        dd['s'] = s\n",
    "        dd['scov'] = scov\n",
    "        if clean_summary:\n",
    "            summ.resid = None\n",
    "            summ.fittedvalues = None\n",
    "        dd['summary'] = summ\n",
    "\n",
    "        dd['lilliefors_test_st'] = summ.lilliefors_test_st\n",
    "        dd['lilliefors_test_pv'] = summ.lilliefors_test_pv\n",
    "        dd['jarque_bera_test_st'] = summ.jarque_bera_test_st\n",
    "        dd['jarque_bera_test_pv'] = summ.jarque_bera_test_pv\n",
    "        dd['jarque_bera_test_skew'] = summ.jarque_bera_test_skew\n",
    "        dd['jarque_bera_test_kurtosis'] = summ.jarque_bera_test_kurtosis\n",
    "        \n",
    "        dd['coefp_sig_max'] = np.nan\n",
    "        dd['coefp_sig_min'] = np.nan\n",
    "        if (s.find(r'*') < 0) and dd['varn_pval'] < 0.05:\n",
    "            dd['coefp_sig_max'] = dd['varn_coef'] \n",
    "            dd['coefp_sig_min'] = dd['varn_coef'] \n",
    "            \n",
    "        strs = fet0.query('index.str.contains(@varn) and pval <= 0.05')['cond'].values\n",
    "        condssig = ','.join(strs)\n",
    "        dd['condssig'] = condssig\n",
    "\n",
    "        dd['R2_marginal'] = summ.pseudo_r2['R2_marginal']\n",
    "        dd['R2_cond'] = summ.pseudo_r2['R2_conditional']\n",
    "\n",
    "        print(varn,s,scov,converged,converged2)\n",
    "        if DEBUG:\n",
    "            display(summ)\n",
    "        if converged and s.find(r'*') >= 0:\n",
    "            interactions = fet0.query('index.str.contains(\":\")').index.values\n",
    "            fet0int = fet0.loc[interactions]\n",
    "                                    \n",
    "            fet0['coefp'] = np.nan\n",
    "            fet0.loc[fet0int.index,'coefp'] =fet0.loc[fet0int.index,'coef'] + dd['varn_coef']\n",
    "            fet0.loc[fet0.query('index == @varn').index,'coefp'] = dd['varn_coef']            \n",
    "            \n",
    "            fet0int = fet0.loc[interactions] # for it to have coefp now                \n",
    "            \n",
    "            fet0sig = fet0.query('pval <= 0.05')\n",
    "            if len(fet0sig):\n",
    "                dd['coefp_sig_max'] = fet0sig['coefp'].max()\n",
    "                dd['coefp_sig_min'] = fet0sig['coefp'].min()\n",
    "            dd['coefp_max'] = fet0['coefp'].max()\n",
    "            dd['coefp_min'] = fet0['coefp'].min()\n",
    "            \n",
    "            #fet0['is_nm_intercept'] = fet0tmp['index'].str.match(regex)\n",
    "            fet0['is_nm_intercept'] = fet0['index'].str.match(regex)\n",
    "            dd['intercept_nm_min'] = fet0.query('is_nm_intercept == True').coef.min()\n",
    "            dd['intercept_nm_max'] = fet0.query('is_nm_intercept == True').coef.max()\n",
    "            dd['intercept_nm_pval_min'] = fet0.query('is_nm_intercept == True').pval.min()\n",
    "            dd['intercept_nm_pval_max'] = fet0.query('is_nm_intercept == True').pval.max()\n",
    "\n",
    "            rs = fet0int.query('pval <= 0.05')\n",
    "            lsig = len( rs )            \n",
    "\n",
    "            num_sig_inter = lsig + int( cnv(d[varn]['pval']) <= 0.05 ) # number of coefs that are signif\n",
    "            num_sig_inter_nm = lsig  # number of corrections that are significant\n",
    "                \n",
    "            num_sig_inter_pos = int( dd['varn_coef'] > 0 ) * int( dd['varn_pval'] < 0.05 )\n",
    "            num_inter_pos = int( dd['varn_coef'] > 0 ) \n",
    "            for ir,r in rs.iterrows():\n",
    "                coef_full = d[varn]['coef'] + float(r['coef'])\n",
    "                num_sig_inter_pos += int(coef_full > 0)\n",
    "            dd['coefp_nm_max'] = fet0int['coefp'].max()  # nm means not meain effect\n",
    "            dd['coefp_nm_min'] = fet0int['coefp'].min()\n",
    "            \n",
    "            dd['num_inter'] = len(interactions) + 1                        \n",
    "            dd['num_sig_inter'] = num_sig_inter\n",
    "            dd['num_sig_inter_pos'] = num_sig_inter_pos \n",
    "\n",
    "            dd['num_sig_inter_nm'] = num_sig_inter_nm\n",
    "        \n",
    "            if scov == \"1\" and DEBUG:\n",
    "                raise ValueError('st')        \n",
    "#        display(summ.wmess)\n",
    "        del summ,fet,fet0,tab        \n",
    "\n",
    "        mixmr += [dd.copy()]\n",
    "        ind += 1\n",
    "    #break\n",
    "assert len(mixmr)\n",
    "mixmr= pd.DataFrame(mixmr)\n",
    "print('completed')\n",
    "\n",
    "mixmr['inter'] = mixmr['s'].str.contains(r'\\*') # contains treats string as a regular expression\n",
    "mixmr['sshrt'] = mixmr['s'].str[10:]\n",
    "\n",
    "def f(row):\n",
    "    varn = row['varn']\n",
    "    s = row['sshrt']\n",
    "    if isinstance(s,str):\n",
    "        s = s.replace(varn,'{varn}')\n",
    "    return s\n",
    "mixmr['sshrt'] = mixmr.apply(f,1)\n",
    "\n",
    "print(len(prl),len(mixmr))\n",
    "\n",
    "mixmr.loc[mixmr['num_inter'].isna(),'num_inter'] = 0\n",
    "mixmr = mixmr.loc[~mixmr.s.str.contains(r'\\* error_pscadj_abs')] # they are weird, because not prev\n",
    "\n",
    "# take newer calcs\n",
    "grp = mixmr.groupby(['cocoln','varn','sshrt','scov','transform'])\n",
    "mixmr = aggRows(mixmr,'dt','max', grp =grp )\n",
    "\n",
    "def f(row):\n",
    "    statn = row['varn'][len(row['varn0'])+1:]\n",
    "    hl = row['histlen']\n",
    "    hl_l = len(str(hl))\n",
    "    statn = statn[:-hl_l]\n",
    "    return statn\n",
    "                  \n",
    "mixmr['statn'] = mixmr.apply(f,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ff7931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#s2summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42c6cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "load = 1\n",
    "save = 0\n",
    "if load:\n",
    "    #date = ''\n",
    "    mll_fn = 'mll_2025-07-20_00:16:50'\n",
    "    mixmr = pd.read_pickle(pjoin(prl_path_data,f'{mll_fn}.pkl.zip') )\n",
    "else:\n",
    "    if save:    \n",
    "        s = str(datetime.now())[:-7].replace(' ','_')\n",
    "        mixmr.to_pickle(pjoin(prl_path_data, f'mll_{s}.pkl.zip'), compression='zip')\n",
    "        print('saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3efca91",
   "metadata": {},
   "source": [
    "# after collection (assuming mixmr is ready to use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98aa990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check that we don't have repeats\n",
    "sz = mixmr.groupby(['cocoln','varn','sshrt','scov','transform']).size()\n",
    "print(sz.max())\n",
    "#display(sz)\n",
    "assert sz.max() == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff1911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model (in R2 sense) that has significant pvalue\n",
    "inds = mixmr.query('varn_pval <= 0.05 and cocoln == \"env\"').\\\n",
    "    sort_values(['R2_cond'], ascending=False).head(1).index._data\n",
    "#inds = inds[2:]\n",
    "#[cols_fav]\n",
    "cc = ['Coef.','P>|z|']\n",
    "for ind in inds:\n",
    "    row = mixmr.loc[ind]\n",
    "    print(f'index = {ind} (indprl ={row[\"ind_in_prl\"]}), formula = {row[\"s\"]},'\n",
    "          f'\\n    cov structure = {row[\"scov\"]}')\n",
    "    print('transform = ', row['transform'])\n",
    "    print(f\"R2 conditional = {row['R2_cond']:.4f}, R2 marginal = {row['R2_marginal']:.4f}\")\n",
    "    print(f\"lilliefors_test_pv: {row['lilliefors_test_pv']:.4f}\")\n",
    "    print(f\"jarque_bera_test_pv: {row['jarque_bera_test_pv']:.4f}\")\n",
    "    print(f\"jarque_bera_test_skew: {row['jarque_bera_test_skew']:.4f}\")\n",
    "    print(f\"jarque_bera_test_kurtosis: {row['jarque_bera_test_kurtosis']:.4f}\")\n",
    "    fet = row['summary'].tables[1]\n",
    "    #rowis = fet.index[:-3] # .iloc[:-2]\n",
    "    print(fet[cc])\n",
    "    print('--------------')\n",
    "    #break\n",
    "varnames = list( mixmr.loc[inds]['varn'].values )\n",
    "print(varnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4fa181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot QQ plot\n",
    "%matplotlib inline\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "import statsmodels.api as sm\n",
    "ind_in_prl = mixmr.loc[inds[0],'ind_in_prl']\n",
    "prl_el = prl[ind_in_prl]\n",
    "for k,summ in prl_el['s2summary'].items():\n",
    "    if summ is None:\n",
    "        continue\n",
    "    if summ.resid is None:\n",
    "        continue\n",
    "    print(k)\n",
    "    sm.qqplot(summ.resid, line='s')\n",
    "    plt.title(f'QQ Plot for\\n {k}, \\ntransform: {prl_el[\"transform\"]}')\n",
    "    plt.show()\n",
    "\n",
    "    sns.scatterplot(x=summ.fitted_values, y=summ.resid, alpha=0.5)\n",
    "    plt.axhline(0, color='red', linestyle='--')\n",
    "    plt.xlabel(\"Fitted Values\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    plt.title(f'Residuals vs. Fitted Values\\n {s}\\ntransform: {prl_el[\"transform\"]}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d18a8f",
   "metadata": {},
   "source": [
    "# Before starting ot care about quality of fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1422dbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols_exc = ['histlen','varn0','res','summary','varn_suffix', 's2summary','s']\n",
    "cols_exc = ['histlen','varn0','res','summary','varn_suffix', 's2summary','converged',\n",
    "            'converged2','s', 'excfmt','fet0']\n",
    "cols0 = [c for c in mixmr.columns if c not in cols_exc]; cols0\n",
    "#display(mixmr[cols])\n",
    "\n",
    "cols_fav = ['transform', 'cocoln', 'varn', 'scov', \n",
    " 'coefp_sig_max', 'coefp_sig_min', 'coefp_nm_max', 'coefp_nm_min', \n",
    "    'num_sig_inter_pos','sshrt','condssig','R2_marginal','R2_cond', \n",
    "    'lilliefors_test_pv','jarque_bera_test_pv','jarque_bera_test_skew',\n",
    "    'jarque_bera_test_kurtosis'] #'num_inter',\n",
    "\n",
    "qs = 'cocoln == \"env\" and varn_pval <= 0.05 and converged2 == True and excfmt.isnull()'\n",
    "# with pd.option_context('display.max_rows', None):\n",
    "#     display(mixmr.sort_values('s').query(qs)[cols])\n",
    "    \n",
    "#qs += ' and coefp_sig_max > 0'\n",
    "#display(mixmr.sort_values('s').query(qs)[cols0])\n",
    "display(mixmr.sort_values(['s']).query(qs)[cols_fav])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df11f1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### All positive slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef813b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with significant interactions with ALL positive slopes (so the most inconsistent slopes across conditions)\n",
    "# there is only one for ps_ error_pscadj_abs_invstd7 and the slope size is pretty low\n",
    "cols = [c for c in mixmr.columns if c not in cols_exc]; cols\n",
    "\n",
    "qs = 'converged2 == True'\n",
    "# with pd.option_context('display.max_rows', None):\n",
    "#     display(mixmr.sort_values('s').query(qs)[cols])\n",
    "    \n",
    "qs += ' and coefp_sig_max > 0 and inter == True and num_sig_inter_pos == num_inter'\n",
    "ds_ = mixmr.sort_values(['inter','varn']).query(qs)\n",
    "inds = ds_.index._data\n",
    "display(ds_[cols])\n",
    "\n",
    "ds_2 = mixmr.sort_values(['inter','varn']).query(qs + ' and scov != \"1\"')\n",
    "inds2 = ds_2.index._data\n",
    "print('and with random effects inds = ', inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e87fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 252 has pretty small slopes in pres and rnd, but large in rnd and pert\n",
    "cc = ['Coef.','P>|z|']\n",
    "for ind in inds:\n",
    "    row = mixmr.loc[ind]\n",
    "    print(ind, row['s'], row['scov'])    \n",
    "    fet = row['summary'].tables[1]\n",
    "    #rowis = fet.index[:-3] # .iloc[:-2]\n",
    "    print(fet[cc])\n",
    "    #break\n",
    "varnames = list( mixmr.loc[inds]['varn'].values )\n",
    "print(varnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93e50f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot relationship\n",
    "h=4\n",
    "me = dfcs_fixhistlen.\\\n",
    "    groupby(['subject','env'])[ ['err_sens']+varnames].mean().reset_index()\n",
    "fg,df = relplot_multi(sep_ys_by = 'col', data=me, x='err_sens',ys=varnames, row='env',\n",
    "                     height = h)\n",
    "fg.refline(x=0)\n",
    "fg.refline(y=0)\n",
    "fg.fig.suptitle('Mean within subject')\n",
    "\n",
    "fg,df = relplot_multi(sep_ys_by = 'col', data=dfcs_fixhistlen, x='err_sens',ys=varnames, row='env',\n",
    "                     height = h)\n",
    "fg.refline(x=0)\n",
    "fg.refline(y=0)\n",
    "fg.fig.suptitle('Pooled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f71adfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with at least 1 condition signif different (so with slopes not fully consistent)\n",
    "cols = [c for c in mixmr.columns if c not in cols_exc + ['varn_pval'] ]; cols\n",
    "\n",
    "qs = 'converged2 == True'\n",
    "# with pd.option_context('display.max_rows', None):\n",
    "#     display(mixmr.sort_values('s').query(qs)[cols])\n",
    "qs += ' and coefp_sig_max > 0 and inter == True and num_sig_inter > 1 and coefp_sig_max >= 0.01'\n",
    "qs += ' and not s.str.contains(\"error_pscadj_abs\")'\n",
    "df_ = mixmr.sort_values(['cocoln','inter','varn']).query(qs)\n",
    "inds = df_.index._data\n",
    "#display(df_[cols])\n",
    "\n",
    "df_[cols_fav]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8049ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### some positive slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe70956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with >= 1 significant slopes\n",
    "# there is only one for ps_ error_pscadj_abs_invstd7 and the slope size is pretty low\n",
    "cols = [c for c in mixmr.columns if c not in cols_exc]; cols\n",
    "\n",
    "qs = 'converged2 == True'\n",
    "# with pd.option_context('display.max_rows', None):\n",
    "#     display(mixmr.sort_values('s').query(qs)[cols])\n",
    "    \n",
    "qs += ' and coefp_sig_max > 0 and inter == True and not s.str.contains(\"prev_\")' \n",
    "ds_ = mixmr.sort_values(['inter','varn']).query(qs)\n",
    "inds = ds_.index._data\n",
    "display(ds_[cols])\n",
    "\n",
    "ds_2 = mixmr.sort_values(['inter','varn']).query(qs + ' and scov != \"1\"')\n",
    "inds2 = ds_2.index._data\n",
    "print(f'and with random effects {len(inds2)} inds2 = ', inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d900f753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[c for c in dfc.columns if c.find('error') >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e16c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mixmr.iloc[0]['s2summary'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360fce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_2[cols_fav ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e39e3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first one (with random effects for ps_) is error_pscadj_invstd19, it has rahter small slope (0.022)\n",
    "# and it has a tendency (not signif) to decrease in random (-0.048)\n",
    "\n",
    "# other indices (w/o random effects for env) are for std with high histlen 25+, \n",
    "# they have very high slope in random with strong (not signif) reduction in stable\n",
    "# but it goes doown\n",
    "cc = ['Coef.','P>|z|']\n",
    "for ind in inds2:\n",
    "    row = mixmr.loc[ind]\n",
    "    print(ind, row['s'], '---  ',row['scov'], row['converged2'])    \n",
    "    #print(row['s'], '---  ',row['scov'])    \n",
    "    #display(row['summary'].wmess)\n",
    "    print(row['varn'])#, '---  ',row['scov'])    \n",
    "    fet0 = row['fet0'][['index','cond','coef','coefp','pval']]#.tables[1]\n",
    "    #rowis = fet.index[:-3] # .iloc[:-2]\n",
    "    #display(fet[cc])\n",
    "    display(fet0)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db850c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "###  with just one signif condition (so with slopes kinda consistent across conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8564b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with just one signif condition (so with slopes kinda consistent across conditions)\n",
    "cols = [c for c in mixmr.columns if c not in cols_exc + ['varn_pval'] ]; cols\n",
    "\n",
    "qs = 'converged2 == True'\n",
    "# with pd.option_context('display.max_rows', None):\n",
    "#     display(mixmr.sort_values('s').query(qs)[cols])\n",
    "qs += ' and coefp_sig_max > 0 and inter == True and num_sig_inter == 1 '#'and coefp_sig_max >= 0.01'\n",
    "qs += ' and not s.str.contains(\"error_pscadj_abs\")'\n",
    "df_ = mixmr.sort_values(['cocoln','inter','varn0','histlen']).query(qs)\n",
    "inds = df_.index._data\n",
    "print(len(inds))\n",
    "varnames = mixmr.loc[inds,'varn'].values\n",
    "#display(df_[cols])\n",
    "\n",
    "#df_2 = mixmr.sort_values(['cocoln','inter','varn']).query(qs + ' and scov != \"1\"')\n",
    "#inds = ds_2.index._data\n",
    "#print(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2760bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(set(varnames) )\n",
    "from collections import OrderedDict\n",
    "#my_list = [1, 2, 3, 2, 5, 1]\n",
    "list(OrderedDict.fromkeys(varnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d9cc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(cols)\n",
    "df_[cols_fav] #,'intercept_pval', 'intercept_coef',num_sig_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391aee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first one (with random effects for ps_) is error_pscadj_invstd19, it has rahter small slope (0.022)\n",
    "# and it has a tendency (not signif) to decrease in random (-0.048)\n",
    "\n",
    "# other indices (w/o random effects for env) are for std with high histlen 25+, \n",
    "# they have very high slope in random with strong (not signif) reduction in stable\n",
    "# but it goes doown\n",
    "cc = ['Coef.','P>|z|']\n",
    "for ind in inds:\n",
    "    row = mixmr.loc[ind]\n",
    "    print(ind, row['s'], '---  ',row['scov'], row['converged2'])    \n",
    "    #print(row['s'], '---  ',row['scov'])    \n",
    "    display(row['summary'].wmess)\n",
    "    print(row['varn'])#, '---  ',row['scov'])    \n",
    "    fet = row['summary'].tables[1]\n",
    "    #rowis = fet.index[:-3] # .iloc[:-2]\n",
    "    #display(fet[cc])\n",
    "    display(fet)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf9a97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixmr.varn.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ac880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from figure.plots import relplot_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853515fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plots don't show a very clear relationship between std for high histlen and err_sens\n",
    "fg,df__ = relplot_multi(sep_ys_by = 'row', data=dfcs_fixhistlen,x='err_sens',ys=varnames, col='env')\n",
    "             #row='subject');\n",
    "fg.refline(x=0)\n",
    "fg.refline(y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ecc4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms of error_std for large histlen show that they have fat tail towards zero for many participants\n",
    "dfcs_fixhistlen.query('subject_ind == 13').hist(varnames[-1])\n",
    "dfcs_fixhistlen.hist(varnames[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d622dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(mixmr.query('varn == @varnames[-1]')[cols0])\n",
    "display(mixmr.loc[39].summary.tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd97801",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### --- with more restriction on coefp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a17873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- with more restriction on coefp\n",
    "qs = 'converged2 == True'\n",
    "# with pd.option_context('display.max_rows', None):\n",
    "#     display(mixmr.sort_values('s').query(qs)[cols])\n",
    "qs += ' and coefp_sig_max > 0 and inter == True and num_sig_inter == 1'# and coefp_sig_max >= 0.1'\n",
    "qs += ' and histlen >= 4'\n",
    "#qs += ' and coefp_min > -0.3'\n",
    "df_ = mixmr.sort_values(['cocoln','varn0','histlen','scov']).query(qs)\n",
    "inds = df_.index.values\n",
    "\n",
    "df_[cols_fav] #,'intercept_pval', 'intercept_coef',num_sig_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dcdd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#cc = ['Coef.','P>|z|']\n",
    "for ind in inds:\n",
    "    row = mixmr.loc[ind]\n",
    "    print(ind, row['s'], '---  ',row['scov'], row['coefp_sig_min'])    \n",
    "    fet0 = row['fet0']\n",
    "    display(fet0.iloc[:-1][['index','coef','coefp','pval']])\n",
    "    #rowis = fet.index[:-3] # .iloc[:-2]\n",
    "    #display(fet[cc])\n",
    "    #break\n",
    "print(len(inds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e8680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for small histlen (up to 4 inc)  std has large slope in stable (and small/moderate insignif diff in random)\n",
    "# for large histlen (since 25) std has large slope for random (and moderate/large insignif diff in stable )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5329dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "varnames = mixmr.loc[inds,'varn'].values\n",
    "print(varnames, set(varnames))\n",
    "#varnames_toshow = #[varnames[0]] + [varnames[-1] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5c760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "relplot_multi(data=dfcs_fixhistlen,x='err_sens',ys=varnames_toshow[:1], col='env');\n",
    "relplot_multi(data=dfcs_fixhistlen,x='err_sens',ys=varnames_toshow[1:], col='env');\n",
    "             #row='subject');\n",
    "#sns.relplot(kind='scatter',data=dfcs_fixhistlen, x="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98533e38",
   "metadata": {},
   "source": [
    "### No inter env (for Tan comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25514762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no inter\n",
    "# for env all intercepts are significant\n",
    "# for ps_ all non-random intercepts are significant\n",
    "qs = 'varn_pval <= 0.05 and converged2 == True '\n",
    "# with pd.option_context('display.max_rows', None):\n",
    "#     display(mixmr.sort_values('s').query(qs)[cols])\n",
    "qs += ' and coefp_sig_max > 0 and inter == False and scov != \"1\" and cocoln == \"env\"'\n",
    "# we exclude std3 because it is too close to std2 which is algebraically close to err sens formula\n",
    "qs += ' and not s.str.contains(\"error_pscadj_abs\") and varn != \"error_pscadj_std3\"'\n",
    "#qs += ' and coefp_sig_max >= 1e-3'\n",
    "df_ = mixmr.sort_values(['cocoln','inter','varn0','histlen']).query(qs)\n",
    "inds = df_.index._data\n",
    "#display(df_[cols_fav[:4] + ['intercept_coef','intercept_pval']])\n",
    "display(df_[cols_fav[:4] + ['R2_cond','R2_marginal','intercept_coef','intercept_pval']])\n",
    "print(len(inds))\n",
    "\n",
    "varn_suffixes_nointer = df_['varn_suffix'].unique()\n",
    "print(varn_suffixes_nointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea20eba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_srt = df_.sort_values('varn_coef', ascending=False)[cols_fav + ['varn_pval']]\n",
    "display(df_srt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608d7974",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_.iloc[0]['fet0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581d50c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: apply to env for stable\n",
    "def addcols(df, cocoln, cond, pref, prek_pattern):\n",
    "    '''pref determines names of the output columns'''\n",
    "    #prek = 'C(ps2_)[T.washout]'\n",
    "    prek = prek_pattern.format(cocoln,cond)\n",
    "    #prek = f'C({cocoln})[T.{cond}]'\n",
    "    def f(row):\n",
    "        #fet0 = row['fet0']\n",
    "        varn_cur = row['varn']\n",
    "        #k = prek + f':{varn_cur}'\n",
    "        ps,pvs = row['summary'].params, row['summary'].pvalues\n",
    "        \n",
    "        k = prek\n",
    "        if k not in ps:\n",
    "            return None,None\n",
    "        coef = ps[k]\n",
    "        pv   = pvs[k]            \n",
    "        icpt,icpt_pv = ps[k], pvs[k]\n",
    "\n",
    "        return icpt,icpt_pv\n",
    "    cols = []\n",
    "    for s in ['icpt','icptpv']:\n",
    "        cols += [pref + s]\n",
    "    df[cols] = df.apply(f,1,result_type='expand')\n",
    "    return cols\n",
    "addcols(df_, 'env', 'stable', 's_', 'C({})[T.{}]')    \n",
    "addcols(df_, 'env', 'stable', 'r_', 'Intercept')    \n",
    "df_[cols_fav + ['s_icpt','s_icptpv','r_icpt','r_icptpv']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ced907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#row.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68a07cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "br = df_.query('r_icptpv < 0.05')#\n",
    "#print('random intercept is signif')\n",
    "#display(br[cols_fav + ['s_icpt','s_icptpv','r_icpt','r_icptpv']])\n",
    "hlsig2,s_icpt2,s_icptpv2,r_icpt2,r_icptpv2 =\\\n",
    "    br.iloc[1][['histlen'] + ['s_icpt','s_icptpv','r_icpt','r_icptpv'] ]\n",
    "\n",
    "br = df_.query('s_icptpv < 0.05 and r_icptpv < 0.05')#\n",
    "print('When both intercepts are signif and different')\n",
    "display(br[cols_fav + ['s_icpt','s_icptpv','r_icpt','r_icptpv']])\n",
    "_,s_icpt,s_icptpv,r_icpt,r_icptpv =\\\n",
    "    br.iloc[0][['histlen'] + ['s_icpt','s_icptpv','r_icpt','r_icptpv'] ]\n",
    "histlens_both_signif = br['histlen'].values\n",
    "hlsig = histlens_both_signif\n",
    "hlsig = ', '.join( map(str, hlsig ) )\n",
    "print(histlens_both_signif)\n",
    "\n",
    "rows = br.iloc[[0,-1]]\n",
    "s0_icpt = ('With growing history length the slope estimate grows, while random and stable' \n",
    "      ' intercept values decrease: ')\n",
    "for rowi,row in rows.iterrows():\n",
    "# h1,h2 = histlens_both_signif[[0,-1]]\n",
    "# c1,c2 = print(br['coefp_sig_max'].values[[0,-1]])\n",
    "# r1,r2 = print(br['r_icpt'].values[[0,-1]])\n",
    "# s1,s2 = print(br['s_icpt'].values[[0,-1]])\n",
    "    s = ('for history length {}: slope {:.2f} (p-value = {:.2e}), ' \n",
    "    'random intercept = {:.2e} (p-value = {:.2e})'\n",
    "    'stable intercept correction = {:.2e} (p-value = {:.2e}). ')\\\n",
    "        .format(row['histlen'], row['varn_coef'], row['varn_pval'], row['r_icpt'], row['r_icptpv'],\n",
    "               row['s_icpt'],row['s_icptpv'])\n",
    "    s0_icpt += s\n",
    "print(s0_icpt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6992af",
   "metadata": {},
   "outputs": [],
   "source": [
    "br = df_.nlargest(1,'varn_coef')\n",
    "display(br[cols_fav + ['ind_in_prl']])#[['varn_coef','varn_pval']]\n",
    "row = br.iloc[0]; print(row.name)\n",
    "pv,coef, hlmax = row[['varn_pval','varn_coef','histlen']].values\n",
    "\n",
    "br = df_.nsmallest(1,'varn_coef')\n",
    "display(br[cols_fav + ['ind_in_prl']])#[['varn_coef','varn_pval']]\n",
    "row = br.iloc[0]; print(row.name)\n",
    "pv_min,coef_min, hlmin = row[['varn_pval','varn_coef','histlen']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8387fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfu = df_.groupby(['cocoln','statn'])['histlen'].unique()\n",
    "print( dfu  )\n",
    "lens =  dfu['env']['invstd'] \n",
    "mnl,mxl,diffl = min(lens),max(lens), np.diff(lens)\n",
    "print(mnl,mxl,diffl)\n",
    "lens = ', '.join( map(str, lens ) )\n",
    "#between {mnl} and {mxl}. \n",
    "s = f'''We ran mixed linear models ES ~ error statistics\n",
    "with two conditions (random,stable)\n",
    "without interactions but with random effects. Here \"error statistics\" is one of \n",
    "many possible statistics of previous errors: mean, standard deviation, inverse standard deviation,\n",
    "mean/standard deviation, mean squared/variance.\n",
    "We selected those models that converged and have a significant positive slope.\n",
    "We found that only models with 1 / standard deviation with history lengths {lens}.\n",
    "In by publication by Tan at al [CITE] authors used mean squared/variance with history lengths 20. \n",
    "However for our data this statistics appears to be not the right one.\n",
    "The maximum histlen we tried was 39 so it is possible that for longer lengths same holds, \n",
    "probably because standard deviation stops changing much. \n",
    "History length higher than 6 was increased in 3-trial step.\n",
    "The largest slope {coef:.3f} (p-value = {pv:.2e}) was for history of length {hlmax}.\n",
    "The smallest slope {coef_min:.3f} (p-value = {pv_min:.2e}) was for history of length {hlmin}.\n",
    "The only history lengths for which intercepts for both conditions were significantly \n",
    "positive and different was {hlsig}.'''\n",
    "s += s0_icpt\n",
    "s += '''In all other cases intercepts were not significantly different from zero.\n",
    "'''.replace('\\n',' ').replace('  ',' ')\n",
    "print('\\n'+s)\n",
    "\n",
    "# (intercept for random = {r_icpt:.3f}, it is > 0 \n",
    "# with p-value {r_icptpv:.2e} and for stable it's difference from random was\n",
    "# {s_icpt:.3f}, it is > 0 with p-value {s_icptpv:.2e}). \n",
    "# In addition for history length {hlsig2} the intercept {r_icpt:.3f} for random > 0 was significant \n",
    "# with p-value {r_icptpv:.2e}."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839b640e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### No inter ps2_  (reported in paper as of  07.07.24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4550e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfall.query('subj == \"01\" and ps2_ == \"washout\" and block_name == \"stable1\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9162686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no inter\n",
    "# for env all intercepts are significant\n",
    "# for ps_ all non-random intercepts are significant\n",
    "qs = 'varn_pval <= 0.05 and converged2 == True '\n",
    "# with pd.option_context('display.max_rows', None):\n",
    "#     display(mixmr.sort_values('s').query(qs)[cols])\n",
    "qs += ' and coefp_sig_max > 0 and inter == False and scov != \"1\" and cocoln == \"ps2_\"'\n",
    "# we exclude std3 because it is too close to std2 which is algebraically close to err sens formula\n",
    "qs += ' and not s.str.contains(\"error_pscadj_abs\") and varn != \"error_pscadj_std3\"'\n",
    "#qs += ' and histlen <= 24'\n",
    "#qs += ' and coefp_sig_max >= 1e-05'\n",
    "df_ = mixmr.sort_values(['cocoln','inter','varn0','histlen']).query(qs)\n",
    "inds = df_.index._data\n",
    "#display(df_[cols_fav[:4] + ['intercept_coef','intercept_pval']])\n",
    "display(df_[cols_fav[:4] + ['R2_cond','R2_marginal','intercept_coef','intercept_pval']])\n",
    "print(len(inds))\n",
    "\n",
    "varn_suffixes_nointer = df_['varn_suffix'].unique()\n",
    "print(varn_suffixes_nointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad099d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_srt = df_.sort_values('varn_coef', ascending=False)[cols_fav + ['varn_pval']]\n",
    "display(df_srt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebcca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "br = df_.query('cocoln == \"ps2_\"').nlargest(1,'varn_coef')\n",
    "display(br[cols_fav + ['ind_in_prl']])#[['varn_coef','varn_pval']]\n",
    "row = br.iloc[0]\n",
    "print(row.name)\n",
    "pv,coef, hlmax = row['varn_pval'],row['varn_coef'],row['histlen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d76973",
   "metadata": {},
   "outputs": [],
   "source": [
    "iceptrows = ['Intercept','C(ps2_)[T.pre]','C(ps2_)[T.washout]','C(ps2_)[T.rnd]']\n",
    "display(row['fet0'].set_index('index').loc[iceptrows,['cond','coef','pval']] )\n",
    "display(row['summary'].pvalues.to_frame().loc[iceptrows])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee68190d",
   "metadata": {},
   "source": [
    "For this statistic the intercept at baseline condition (stable perturbation) was not statistically different from zero. Corrections to it at washout and no perturbation conditions were significantly positive (coefficients 0.75 and 0.31 with p-values 9.25e-26 and 1.19e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aceed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfu = df_.groupby(['cocoln','statn'])['histlen'].unique()\n",
    "print( dfu  )\n",
    "\n",
    "lens = dfu['ps2_']['invstd']\n",
    "mnl,mxl,diffl = min(lens),max(lens), np.diff(lens)\n",
    "lens = ', '.join(map(str,lens))\n",
    "print(mnl,mxl,diffl)\n",
    "\n",
    "#between {mnl} and {mxl}. \n",
    "s = f'''We also ran mixed linear models for\n",
    "four conditions (random, zero perturbation, perturbation, washout)\n",
    "without interactions but with random effects. \n",
    "We selected those models that converged and have a significant positive slope.\n",
    "Similar to the case with two conditions above, \n",
    "we found that only models with 1 / standard deviation with historly lengths {lens} \n",
    "satisfy these requirements.\n",
    "This time the maximum histlen we used was 24 because it is the lenght of the shortest condition.\n",
    "The largest slope {coef:.3f} (p-value = {pv:.2e}) was for history of length {hlmax}.\n",
    "'''.replace('\\n',' ').replace('  ',' ')\n",
    "print('\\n'+s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973e04ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for ind in inds:\n",
    "for ind in [4699]:\n",
    "    row = mixmr.loc[ind]\n",
    "    print(ind, row['s'], '---  ',row['scov'], row['coefp_sig_min'])    \n",
    "    print(row['varn'])\n",
    "\n",
    "    display(mixmr.loc[ind].summary.tables[1][['Coef.','P>|z|']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c034284b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### some slopes WITH interaction, only those stats that work for no interactions (reported in paper as of 07.07.24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7fc003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with >= 1 significant slopes\n",
    "# there is only one for ps_ error_pscadj_abs_invstd7 and the slope size is pretty low\n",
    "cols = [c for c in mixmr.columns if c not in cols_exc]; cols\n",
    "\n",
    "qs = 'converged2 == True and cocoln == \"ps2_\" '\n",
    "qs += ' and coefp_sig_max > 0 and inter == True and not s.str.contains(\"prev_\")' \n",
    "qs += ' and varn_suffix.isin(@varn_suffixes_nointer)'\n",
    "# choose those that have more than one signif interaction (not necessarily positive)\n",
    "qs += ' and condssig.str.contains(\",\")'  \n",
    "qs += ' and histlen <= 24'\n",
    "qs += ' and varn0 == \"error_pscadj\"'\n",
    "\n",
    "df_ = mixmr.sort_values(['cocoln','inter','varn_suffix','histlen']).query(qs + ' and scov != \"1\"')\n",
    "\n",
    "display(df_[cols_fav])\n",
    "inds = df_.index._data\n",
    "print(f'and with random effects {len(inds)} inds = ', inds)\n",
    "\n",
    "dftmp = df_.copy()\n",
    "dftmp = dftmp.set_index('histlen', verify_integrity=True)\n",
    "\n",
    "print( dftmp.index.values )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe349581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: apply to env for stable\n",
    "def addcols(df, cocoln, cond, pref):\n",
    "    '''pref determines names of the output columns'''\n",
    "    #prek = 'C(ps2_)[T.washout]'\n",
    "    prek = f'C({cocoln})[T.{cond}]'\n",
    "    def f(row):\n",
    "        #fet0 = row['fet0']\n",
    "        varn_cur = row['varn']\n",
    "        k = prek + f':{varn_cur}'\n",
    "        ps,pvs = row['summary'].params, row['summary'].pvalues\n",
    "        if k not in ps:\n",
    "            return None,None,None,None\n",
    "        coef = ps[k]\n",
    "        pv   = pvs[k]    \n",
    "\n",
    "        k = prek\n",
    "        icpt,icpt_pv = ps[k], pvs[k]\n",
    "\n",
    "        return coef,pv,icpt,icpt_pv\n",
    "    cols = []\n",
    "    for s in ['coef','pv','icpt','icptpv']:\n",
    "        cols += [pref + s]\n",
    "    df[cols] = df.apply(f,1,result_type='expand')\n",
    "    return cols\n",
    "addcols(dftmp, 'ps2_', 'washout', 'w')    \n",
    "dftmp[['varn','R2_cond','varn_coef','varn_pval','intercept_coef','intercept_pval'] + ['wcoef','wpv','wicpt','wicptpv']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b3e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = dftmp.reset_index().iloc[[0,-1]]\n",
    "s0_slope = ('''with growing history length the slope estimate in perturbation grows and\n",
    "the postive significant correction to it in washout as well\n",
    "while random and stable intercept values decrease: ''').replace('\\n',' ')\n",
    "for rowi,row in rows.iterrows():\n",
    "# h1,h2 = histlens_both_signif[[0,-1]]\n",
    "# c1,c2 = print(br['coefp_sig_max'].values[[0,-1]])\n",
    "# r1,r2 = print(br['r_icpt'].values[[0,-1]])\n",
    "# s1,s2 = print(br['s_icpt'].values[[0,-1]])\n",
    "    s = ('for history length {}: ' \n",
    "    'perturbation slope = {:.2e} (p-value = {:.2e}) '\n",
    "    'washout slope correction = {:.2e} (p-value = {:.2e}). ')\\\n",
    "        .format(row['histlen'], row['varn_coef'], row['varn_pval'], row['wcoef'], row['wpv'])\n",
    "    s0_slope += s\n",
    "print(s0_slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435df0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef1,pv1 = dftmp.loc[12][['wcoef','wpv']].values\n",
    "coef2,pv2 = dftmp.loc[15][['wcoef','wpv']].values\n",
    "\n",
    "refcond = 'pert'\n",
    "othercond = 'washout'\n",
    "lens = ', '.join(map(str,df_.histlen.values))\n",
    "s = f'''To check whether the slope changes across conditions, \n",
    "for those statistical measures we found above we also computed mixed linear model with interactions \n",
    "and random effects. We found that only two models had significant slope difference between some conditins:\n",
    "for models with with history lengths = {lens}\n",
    "where in {othercond} condition slopes were significantly different.\n",
    "For all the models the intercept in this condition was not significantly different from the \n",
    "reference condition ({refcond}) but the slope was significantly higher than in reference condition. \n",
    "''' \n",
    "s = s.replace('\\n',' ').replace('  ',' ') + '\\n\\nMore specifically, ' + s0_slope\n",
    "s += ' This is consistent with naive visual inspection of Fig 2A'\n",
    "s += ' suggesting that adaptation is washout is faster than in perturbation stage.'\n",
    "print(s)\n",
    "\n",
    "# For len 12: slope correction {coef1:.3f}, p-value = {pv1:.2e}, \n",
    "# for len 15: slope correction {coef2:.3f}, p-value {pv2:.2e}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae9d8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = ['Coef.','P>|z|']\n",
    "iceptrows = ['Intercept','C(ps2_)[T.pre]','C(ps2_)[T.washout]','C(ps2_)[T.rnd]']\n",
    "fet_icepts = []\n",
    "for ind in inds:\n",
    "    row = mixmr.loc[ind]\n",
    "    print(ind, row['s'], '---  ',row['scov'], row['converged2'])    \n",
    "    #print(row['s'], '---  ',row['scov'])    \n",
    "    #display(row['summary'].wmess)\n",
    "    print(row['varn'])#, '---  ',row['scov'])    \n",
    "    fet0 = row['fet0'][['index','cond','coef','coefp','pval']]#.tables[1]\n",
    "    #rowis = fet.index[:-3] # .iloc[:-2]\n",
    "    #display(fet[cc])\n",
    "    #display(fet0)\n",
    "    fet_icept = row['fet0'].set_index('index').loc[iceptrows,['cond','coef','pval_full']]\n",
    "    fet_icept['histlen'] = row['histlen']\n",
    "    fet_icepts += [fet_icept]\n",
    "    display( fet_icept )\n",
    "fet_icepts = pd.concat(fet_icepts)\n",
    "fet_icepts = fet_icepts.reset_index()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb707df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fet_icepts = fet_icepts.reset_index()    \n",
    "fet_icepts.groupby(['index','cond'])[['coef','pval_full']].describe(percentiles=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75ec414",
   "metadata": {},
   "source": [
    "### Table for supp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9142a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v1, where I take those when in ANY condition one coef was signif and pos\n",
    "qs = 'converged2 == True '\n",
    "# with pd.option_context('display.max_rows', None):\n",
    "#     display(mixmr.sort_values('s').query(qs)[cols])\n",
    "#    and coefp_sig_max > 0 and \n",
    "\n",
    "# with interactions but with simple covariance\n",
    "qs += ' and inter == True and scov != \"1\" and cocoln == \"ps2_\"'\n",
    "# we exclude std3 because it is too close to std2 which is algebraically close to err sens formula\n",
    "qs += ' and not s.str.contains(\"error_pscadj_abs\") and varn != \"error_pscadj_std3\"'\n",
    "qs += ' and histlen <= 24'\n",
    "qs += ' and coefp_sig_max >= 1e-05'\n",
    "#qs += ' and coefp_min >= 0'   # all positive\n",
    "df_ = mixmr.sort_values(['cocoln','inter','varn0','varn_suffix','histlen']).query(qs)\n",
    "\n",
    "df_['all_slopes_pos'] = (df_['coefp_min'] >= 0) # smallest correcte coef is non-neg\n",
    "df_['all_slopes_equal'] = (df_['num_sig_inter_nm'] == 0) # all non-main interations are non-significant\n",
    "df_['all_intercepts_equal'] = (df_['intercept_nm_pval_max'] >= 0.05) # all non-main intercepts are non-significant\n",
    "\n",
    "from bmp_behav_proc import formatRecentStatVarnames\n",
    "df_['stat_name_nice'] = df_['varn_suffix'].apply(lambda x: formatRecentStatVarnames(['_'+x], histlen_str = '')[0][1:] )\n",
    "print(len(df_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f85a2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2, where I take those when in main effect was signif and pos\n",
    "qs = 'converged2 == True '\n",
    "# with pd.option_context('display.max_rows', None):\n",
    "#     display(mixmr.sort_values('s').query(qs)[cols])\n",
    "#    and coefp_sig_max > 0 and \n",
    "\n",
    "# with interactions but with simple covariance\n",
    "qs += ' and inter == True and scov != \"1\" and cocoln == \"ps2_\"'\n",
    "# we exclude std3 because it is too close to std2 which is algebraically close to err sens formula\n",
    "qs += ' and not s.str.contains(\"error_pscadj_abs\") and varn != \"error_pscadj_std3\"'\n",
    "qs += ' and histlen <= 24'\n",
    "qs += ' and varn_coef >= 1e-05 and varn_pval <= 0.05'\n",
    "#qs += ' and coefp_min >= 0'   # all positive\n",
    "df_ = mixmr.sort_values(['cocoln','inter','varn0','varn_suffix','histlen']).query(qs)\n",
    "\n",
    "df_['all_slopes_pos'] = (df_['coefp_min'] >= 0) # smallest correcte coef is non-neg\n",
    "df_['all_slopes_equal'] = (df_['num_sig_inter_nm'] == 0) # all non-main interations are non-significant\n",
    "df_['all_intercepts_equal'] = (df_['intercept_nm_pval_max'] >= 0.05) # all non-main intercepts are non-significant\n",
    "\n",
    "from bmp_behav_proc import formatRecentStatVarnames\n",
    "df_['stat_name_nice'] = df_['varn_suffix'].apply(lambda x: formatRecentStatVarnames(['_'+x], histlen_str = '')[0][1:] )\n",
    "print(len(df_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3c7ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_['coefp_sig_range'] = df_['coefp_sig_max'] - df_['coefp_sig_min']\n",
    "df_['coefp_sig_range_frac'] = df_['coefp_sig_range'] / df_['coefp_sig_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0180db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- whether all slopes are positive\n",
    "#- whether all slopes are equal,\n",
    "#- whether all intercepts are equal, whether\n",
    "cols_R = ['cocoln','histlen','varn0','varn_suffix','num_sig_inter',\n",
    "          'sshrt','all_slopes_pos','all_slopes_equal','all_intercepts_equal']\n",
    "df_[cols_R]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3f535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.query('varn0 == \"error_pscadj\" and varn_suffix == \"invstd\"')[['histlen','varn_coef','coefp_min','coefp_max','coefp_sig_max']]#.coefp_max#.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7079e360",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_Rf = ['histlen','stat_name_nice','all_slopes_pos','all_slopes_equal','all_intercepts_equal', \n",
    "           'coefp_sig_range_frac_pct_nice','R2_marginal_pct','R2_cond_pct']\n",
    "df_['R2_marginal_pct'] = df_['R2_marginal'] * 100\n",
    "df_['R2_cond_pct'] = df_['R2_cond'] * 100\n",
    "dfres0 = df_.query('varn0 == \"error_pscadj\"').copy()\n",
    "dfres0['coefp_sig_range_frac_pct'] = dfres0['coefp_sig_range_frac'] * 100\n",
    "dfres0['coefp_sig_range_frac_pct_nice'] = dfres0['coefp_sig_range_frac_pct'].apply(lambda x: f'{x:.0f}%')\n",
    "dfres = dfres0[cols_Rf].rename(columns={'histlen':'history length', \n",
    "        'stat_name_nice':'window statistic formula', 'all_slopes_pos':'all slopes positive',\n",
    "        'all_slopes_equal':'all slopes equal','all_intercepts_equal':'all intercepts equal',\n",
    "                                       'coefp_sig_range_frac_pct_nice':'max slope change'})\n",
    "with pd.option_context('display.precision', 1):\n",
    "    display(dfres)\n",
    "dfres.to_csv(pjoin(path_fig, 'behav', 'Tanlike_statistics_summary_table.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f23c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detailed\n",
    "inds = df_.query('varn0 == \"error_pscadj\" and histlen.isin([17,18,19,20,21,22])').sort_values('histlen').index._data\n",
    "#inds = df_.query('varn0 == \"error_pscadj\" and histlen.isin([14])').sort_values('histlen').index._data\n",
    "inds = df_.query('varn0 == \"error_pscadj\" and histlen.isin([7])').sort_values('histlen').index._data\n",
    "\n",
    "cc = ['Coef.','P>|z|']\n",
    "iceptrows = ['Intercept','C(ps2_)[T.pre]','C(ps2_)[T.washout]','C(ps2_)[T.rnd]']\n",
    "fet_icepts = []\n",
    "for ind in inds:\n",
    "    row = mixmr.loc[ind]\n",
    "    print(ind, row['s'], '---  ',row['scov'], row['converged2'])    \n",
    "    #print(row['s'], '---  ',row['scov'])    \n",
    "    #display(row['summary'].wmess)\n",
    "    print(row['varn'])#, '---  ',row['scov'])    \n",
    "    fet0 = row['fet0'][['index','cond','coef','coefp','pval']]#.tables[1]\n",
    "    #rowis = fet.index[:-3] # .iloc[:-2]\n",
    "    #display(fet[cc])\n",
    "    display(fet0)\n",
    "    fet_icept = row['fet0'].set_index('index').loc[iceptrows,['cond','coef','pval_full']]\n",
    "    fet_icept['histlen'] = row['histlen']\n",
    "    fet_icepts += [fet_icept]\n",
    "    display( fet_icept )\n",
    "fet_icepts = pd.concat(fet_icepts)\n",
    "fet_icepts = fet_icepts.reset_index()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11068d60",
   "metadata": {},
   "source": [
    "## corr for all without regard for env/ps2_ (of ES and windows-stat measues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c10306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean across\n",
    "ttrs_pos = cocoln2corrs_mesubj['None'].query('pval <= 0.05 and r > 0')\n",
    "varnames = list(ttrs_pos.reset_index()['varn'].values)\n",
    "#print(varnames )\n",
    "print('For mean,then corr {} varnames are >0 correlated'.format(len(varnames) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e486f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all trial together\n",
    "def f(df):\n",
    "    if len(df) == 0:\n",
    "        return None\n",
    "    ttrs = compare0(df, 'r', cols_addstat=['r'])\n",
    "    return ttrs\n",
    "m2vns={}\n",
    "\n",
    "    # include groups is whether df that f receives as arg has grouping columns or not\n",
    "ttrs = cocoln2corrs_per_subj.query('cocoln == \"None\"').\\\n",
    "    groupby(['varn','method'], observed=True).apply(f, include_groups=False)\n",
    "print(getAddInfo())\n",
    "#display(ttrs.query('pval <= 0.05 and ttstr == \"r < 0\"')\\\n",
    "#        [['pval','ttstr']])\n",
    "\n",
    "ttrs_pos = ttrs.query('pval <= 0.05 and ttstr == \"r > 0\"')\n",
    "#display(ttrs_pos[['pval','ttstr']])\n",
    "for method in cocoln2corrs_per_subj.method.unique():\n",
    "    varnames = ttrs_pos.loc[ttrs_pos.index.get_level_values('method') == method].reset_index()['varn'].values\n",
    "    varnames = list(varnames)\n",
    "    #varnames = list(ttrs_pos[(None,method)])\n",
    "    #print(varnames )\n",
    "    print(method, len(varnames), ' varnames are >0 correlated' )\n",
    "    m2vns[method] = varnames\n",
    "\n",
    "#print( ', '.join(varnames) )\n",
    "\n",
    "\n",
    "#print ('Dif between methods ',set(m2vns['spearman']) ^ set(m2vns['shepherd']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217f5883",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrs_pos = ttrs_pos.query('method == \"spearman\"')\n",
    "ttrs_pos = ttrs_pos.sort_values(['pval'])\n",
    "ttrs_pos[['pval','T','r_mean','r_std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1352a3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrs_pos = ttrs_pos.query('varn.str.contains(\"_invstd\")').sort_values(['r_mean'], ascending=False)\n",
    "ttrs_pos[['pval','T','r_mean','r_std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b649a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ttrs_pos.query('varn.str.endswith(\"std2\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e9860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ = pd.DataFrame( {'varn':m2vns['spearman'] } )\n",
    "#df_['']\n",
    "\n",
    "# std2\n",
    "# invstd 4-39\n",
    "# abs invstd 2-39\n",
    "# abs mav d var 4-39\n",
    "\n",
    "m2vns['spearman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e10a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ES vs windows stats\n",
    "import warnings\n",
    "varnames = list(ttrs_pos.reset_index()['varn'].values)\n",
    "if len(varnames) <= 10:\n",
    "    print(varnames)\n",
    "    for env in ['stable','random']:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "            me = dfcs_fixhistlen.query('env == @env').\\\n",
    "                groupby(['subject','env'])[['err_sens']+varnames].mean().reset_index()\n",
    "            fg = sns.pairplot(data=me, \n",
    "                     y_vars = ['err_sens'], hue='env',\n",
    "                         x_vars=['err_sens'] + varnames)#,corner=1)\n",
    "\n",
    "    me = dfcs_fixhistlen.\\\n",
    "        groupby(['subject'])[['err_sens']+varnames].mean().reset_index()\n",
    "    fg = sns.pairplot(data=me, \n",
    "             y_vars = ['err_sens'], \n",
    "                 x_vars=['err_sens'] + varnames)#,corner=1)\n",
    "else:\n",
    "    print('Too long list of varnames ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f909509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765e4a4f",
   "metadata": {},
   "source": [
    "## corr within env (of ES and windows-stat measues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a8f1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mesubj (useless)\n",
    "# it gives 0 because for random it does not make sense to average across participants\n",
    "# because randomness is not consistent across them\n",
    "env2varnames = {}\n",
    "ttrs = cocoln2corrs_mesubj['env']\n",
    "for env in ['stable','random']:\n",
    "    ttrs_pos = ttrs.query('pval <= 0.05 and r > 0 and'\n",
    "                         ' env == @env')\n",
    "#display(ttrs_pos[['pval','ttstr']])\n",
    "    varnames = list(ttrs_pos.reset_index()['varn'].values)\n",
    "    print(env,len(varnames))\n",
    "    env2varnames[env] = varnames\n",
    "varnames_isec = set(env2varnames['stable']) & set(env2varnames['random'])\n",
    "varnames_isec = list(varnames_isec)\n",
    "print('random ', set(env2varnames['random']))\n",
    "print('isec varnames',varnames_isec  )\n",
    "\n",
    "print('For mean, stable&random corr {} varnames are >0 correlated'.format(len(varnames) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0674e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find with windows stats are positive bot for random AND for stable\n",
    "from behav_proc import compare0\n",
    "def f(df):\n",
    "    if len(df) == 0:\n",
    "        return None\n",
    "    ttrs_ = compare0(df, 'r')\n",
    "    return ttrs_\n",
    "for method in cocoln2corrs_per_subj.method.unique():\n",
    "    ttrs = cocoln2corrs_per_subj.query('cocoln == \"env\" and method == @method').\\\n",
    "        groupby(['varn','env'], observed=True).apply(f)\n",
    "    print(getAddInfo())\n",
    "    #display(ttrs.query('pval <= 0.05 and thr in @thrs')\\\n",
    "    #        [['pval','ttstr']])\n",
    "\n",
    "    ttrs_pos = ttrs.query('pval <= 0.05 and ttstr == \"r > 0\"')\n",
    "    print('All positive, both envs (separately)')\n",
    "    #display(ttrs_pos[['pval','ttstr']])\n",
    "\n",
    "    env2varnames = {}\n",
    "    for env in ['stable','random']:\n",
    "        ttrs_pos = ttrs.query('pval <= 0.05 and ttstr == \"r > 0\" and'\n",
    "                             ' env == @env')\n",
    "    #display(ttrs_pos[['pval','ttstr']])\n",
    "        varnames = list(ttrs_pos.reset_index()['varn'].values)\n",
    "        env2varnames[env] = varnames\n",
    "    varnames_isec = set(env2varnames['stable']) & set(env2varnames['random'])\n",
    "    varnames_isec = list(varnames_isec)\n",
    "    print(method, 'isec varnames',varnames_isec  )\n",
    "#print(varnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0730e8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be put into paper\n",
    "mer = cocoln2corrs_per_subj.query('cocoln == \"env\"').\\\n",
    "    groupby(['varn','env'], observed=True)['r'].mean()\n",
    "\n",
    "print(getAddInfo(),'\\n')\n",
    "r = ttrs.query('pval <= 0.05 and ttstr == \"r > 0\" '\n",
    "    ' and varn.isin(@varnames_isec)').reset_index()[['varn','env','pval']].set_index(['varn','env'])\n",
    "#d = r.T.to_dict()\n",
    "#print(d)\n",
    "\n",
    "for varn in varnames_isec:\n",
    "    st = r.loc[(varn,'stable'),'pval']\n",
    "    ra = r.loc[(varn,'random'),'pval']\n",
    "    stabr = mer[(varn,'stable')]\n",
    "    randr = mer[(varn,'random')]\n",
    "    \n",
    "    s = (f\"{varn}: For random r>0 has p-val={ra:.2e} (mean r = {randr:.3f})\"\n",
    "        f\" and for stable r>0 has p-val={st:.2e} (mean r = {stabr:.3f})\")\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4896c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#me['env']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e932d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "h=4\n",
    "varnames_toshow = varnames_isec[1:]\n",
    "fg,df = relplot_multi(sep_ys_by = 'col', data=dfcs_fixhistlen, x='err_sens',ys=varnames_toshow, row='env',\n",
    "                     height = h)\n",
    "for ax in fg.axes.flatten():\n",
    "    ttl = ax.get_title().replace('__varname = ','').replace('env = ','')\n",
    "    ax.set_title(ttl)\n",
    "\n",
    "fg.refline(x=0)\n",
    "fg.refline(y=0)\n",
    "fg.fig.suptitle('Pooled')\n",
    "plt.tight_layout()\n",
    "\n",
    "me = dfcs_fixhistlen.\\\n",
    "    groupby(['subject','env'])[['err_sens']+varnames_toshow].mean().reset_index()\n",
    "fg,df = relplot_multi(sep_ys_by = 'col', data=me, x='err_sens',ys=varnames_toshow, row='env',\n",
    "                     height = h)\n",
    "for ax in fg.axes.flatten():\n",
    "    ttl = ax.get_title().replace('__varname = ','').replace('env = ','')\n",
    "    ax.set_title(ttl)\n",
    "fg.refline(x=0)\n",
    "fg.refline(y=0)\n",
    "fg.fig.suptitle('Mean within subject')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f0f360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fg = sns.relplot(data=dfcs_fixhistlen, col='subject',\n",
    "#     y = 'err_sens', x=varnames_isec[0], row='env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900a0331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from behav_proc import formatRecentStatVarnames\n",
    "isec_nice = formatRecentStatVarnames(varnames_isec)\n",
    "display(isec_nice)\n",
    "print('; '.join(isec_nice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39925702",
   "metadata": {},
   "outputs": [],
   "source": [
    "isec = set(env2varnames['stable']) & set(env2varnames['random'])\n",
    "if len(isec):\n",
    "    print('If we fix the history length first, then compute correlation '\n",
    "      'within participant (separately for both environments)'\n",
    "      ' and then choose variables for which r>0 stat significantly in both environments'\n",
    "      ' simultaneously, we get ',', '.join(list(isec) ) )\n",
    "else:\n",
    "    print('We get nothing signif postive in both separately')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2462ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ttrs.query('varn == \"error_pscadj_invstd10\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700ca530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "varnames = list(ttrs_pos.reset_index()['varn'].values)\n",
    "print(varnames)\n",
    "for env in ['stable','random']:\n",
    "    plt.figure()\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "        fg = sns.pairplot(data=dfcs.query('env == @env').\\\n",
    "            groupby(['subject','env'])[['err_sens']+env2varnames[env]].mean().reset_index(), \n",
    "            y_vars = ['err_sens'], hue='env',\n",
    "            x_vars=['err_sens'] + env2varnames[env])#,corner=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7fd608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You are an expert in python pandas and data science.\n",
    "# I have a pandas dataframe with the following columns\n",
    "# ttrs_pos.columns = ['alt', 'val1', 'ttstr','varn','env']\n",
    "# 'ttstr' can take two possible string values '>0' and '<0'. \n",
    "# 'env' can take two string values 'stable' and 'random'. \n",
    "# 'varn' can take several possible string values.\n",
    "# I want to select rows that have ttstr = '>0' for both stable and random values of 'env'.\n",
    "# How to do it?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "error-sensitivity-across-space-time-var",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
